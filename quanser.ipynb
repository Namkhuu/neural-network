{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8ceea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.layers import Concatenate\n",
    "from collections import deque\n",
    "import random\n",
    "from quanser.hardware import HIL \n",
    "from pal.products.qube import QubeServo3\n",
    "from pal.utilities.math import SignalGenerator, ddt_filter\n",
    "from pal.utilities.scope import Scope\n",
    "from threading import Thread\n",
    "import time\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49e7c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
    "        return (np.array(states, dtype=np.float32),\n",
    "            np.array(actions, dtype=np.float32),\n",
    "            np.array(rewards, dtype=np.float32),\n",
    "            np.array(next_states, dtype=np.float32),\n",
    "            np.array(dones, dtype=np.float32))\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "def soft_update(target_weights, online_weights, tau=0.005):\n",
    "    for (target, online) in zip(target_weights, online_weights):\n",
    "        target.assign(target * (1 - tau) + online * tau) \n",
    "\n",
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8509c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x204bc80d0c0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size = 4\n",
    "action_size = 1\n",
    "gamma = 0.99 # discount rate\n",
    "learning_rate = 0.001 # learning rate\n",
    "\n",
    "# Define the actor model\n",
    "states_inputs = Input(shape=(state_size,))\n",
    "dense = Dense(32, activation='relu')(states_inputs)\n",
    "dense = Dense(32, activation='relu')(dense)\n",
    "outputs = Dense(action_size, activation='tanh')(dense)\n",
    "outputs = keras.layers.Lambda(lambda x: x * 2.5)(outputs)  \n",
    "actor_model = Model(inputs=states_inputs, outputs=outputs)\n",
    "\n",
    "# Critic 1\n",
    "state_input1 = Input(shape=(state_size,))\n",
    "action_input1 = Input(shape=(action_size,))\n",
    "concat1 = Concatenate()([state_input1, action_input1])\n",
    "dense1 = Dense(32, activation='relu')(concat1)\n",
    "dense1 = Dense(32, activation='relu')(dense1)\n",
    "sigmoid_layer = Dense(1, activation='linear')(dense1)\n",
    "output1 = Dense(1)(sigmoid_layer)\n",
    "critic_model1 = Model([state_input1, action_input1], output1)\n",
    "\n",
    "# Critic 2\n",
    "state_input2 = Input(shape=(state_size,))\n",
    "action_input2 = Input(shape=(action_size,))\n",
    "concat2 = Concatenate()([state_input2, action_input2])\n",
    "dense2 = Dense(32, activation='relu')(concat2)\n",
    "dense2 = Dense(32, activation='relu')(dense2)\n",
    "sigmoid_layer2 = Dense(1, activation='linear')(dense2)\n",
    "output2 = Dense(1)(sigmoid_layer2)\n",
    "critic_model2 = Model([state_input2, action_input2], output2)\n",
    "\n",
    "# try:\n",
    "#     actor_model.load_weights('saves/quanser/actor_model.weights.h5')\n",
    "#     critic_model1.load_weights('saves/quanser/critic_model1.weights.h5')\n",
    "#     critic_model2.load_weights('saves/quanser/critic_model2.weights.h5')\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "actor_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "critic_optimizer1 = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "critic_optimizer2 = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "target_actor = keras.models.clone_model(actor_model)\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "\n",
    "target_critic1 = keras.models.clone_model(critic_model1)\n",
    "target_critic1.set_weights(critic_model1.get_weights())\n",
    "target_critic2 = keras.models.clone_model(critic_model2)\n",
    "target_critic2.set_weights(critic_model2.get_weights())\n",
    "\n",
    "ckpt = tf.train.Checkpoint(actor_optimizer=actor_optimizer,\n",
    "                           critic_optimizer1=critic_optimizer1, \n",
    "                           critic_optimizer2=critic_optimizer2)\n",
    "\n",
    "# Restore the latest checkpoint with optimizer states\n",
    "ckpt.restore(tf.train.latest_checkpoint(\"saves/quanser/optimizers_ckpt\")).expect_partial()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "844cf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # squareWave = SignalGenerator().square(np.pi/4, 5)\n",
    "# # next(squareWave)\n",
    "# k_p, k_d = (4.000, 0.175)\n",
    "# frequency = 500  # Hz\n",
    "# state_theta_dot = np.array([0,0], dtype=np.float64)\n",
    "# state_alpha_dot = np.array([0,0], dtype=np.float64)\n",
    "# with QubeServo3(hardware = 1, pendulum = 1, frequency=frequency) as board:\n",
    "#     while True:\n",
    "#         # Have to initialize the board first before reading motorPosition or it won't read\n",
    "#         board.read_outputs()\n",
    "#         theta = board.motorPosition \n",
    "#         alpha = -board.pendulumPosition \n",
    "        \n",
    "#         if np.abs(theta) > np.pi/4:\n",
    "#             pen = 500\n",
    "#         else:\n",
    "#             pen = 0\n",
    "\n",
    "#         theta_dot, state_theta_dot = ddt_filter(theta, state_theta_dot, 50, 1/frequency)\n",
    "#         # u - input\n",
    "#         # state - previous state returned by this function -- initialize to np.array([0,0], dtype=np.float64)\n",
    "#         # Ts - sample time in seconds\n",
    "#         # A - filter bandwidth in rad/s\n",
    "#         alpha_dot, state_alpha_dot = ddt_filter(alpha, state_alpha_dot, 100, 1/frequency)\n",
    "#         reward = -((\n",
    "#                     alpha**2\n",
    "#                 ))\n",
    "#         reward = float(reward - pen) \n",
    "#         print(f\"Theta: {theta:.3f}, Theta dot: {theta_dot:.3f}, Alpha: {alpha:.3f}, Alpha dot: {alpha_dot:.3f}\", \n",
    "#               f\"Reward: {reward:.3f}\")\n",
    "# #         time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntk00\\AppData\\Local\\Temp\\ipykernel_27296\\2255423053.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  reward = float(reward - pen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Reward: -12.3059, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1416 alpha_dot: -285.5993 voltage: 2.21 theta: -0.0000 theta_dot: 0.0000\n",
      "Epoch 2, Total Reward: -10.1326, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1416 alpha_dot: -191.1863 voltage: 2.93 theta: -0.0000 theta_dot: 0.0000\n",
      "Epoch 3, Total Reward: -9.8824, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1416 alpha_dot: -127.9842 voltage: 2.77 theta: -0.0031 theta_dot: -0.1322\n",
      "Epoch 4, Total Reward: -9.9741, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1416 alpha_dot: -85.6754 voltage: 2.32 theta: -0.0031 theta_dot: -0.1082\n",
      "Epoch 5, Total Reward: -9.8316, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1355 alpha_dot: -56.8459 voltage: 2.28 theta: -0.0061 theta_dot: -0.2208\n",
      "Epoch 6, Total Reward: -9.9071, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1324 alpha_dot: -37.7749 voltage: 2.72 theta: -0.0123 theta_dot: -0.4590\n",
      "Epoch 7, Total Reward: -9.7552, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1232 alpha_dot: -24.5013 voltage: 2.76 theta: -0.0184 theta_dot: -0.6540\n",
      "Epoch 8, Total Reward: -9.7419, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1170 alpha_dot: -15.8946 voltage: 2.54 theta: -0.0276 theta_dot: -0.9458\n",
      "Epoch 9, Total Reward: -9.7868, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1048 alpha_dot: -9.6260 voltage: 1.99 theta: -0.0368 theta_dot: -1.1986\n",
      "Epoch 10, Total Reward: -9.6834, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0956 alpha_dot: -5.6578 voltage: 1.54 theta: -0.0460 theta_dot: -1.3916\n",
      "Epoch 11, Total Reward: -9.5143, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0833 alpha_dot: -2.7733 voltage: 1.42 theta: -0.0583 theta_dot: -1.6957\n",
      "Epoch 12, Total Reward: -9.4471, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0680 alpha_dot: -0.5634 voltage: 1.16 theta: -0.0736 theta_dot: -2.0768\n",
      "Epoch 13, Total Reward: -9.3388, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0526 alpha_dot: 0.9160 voltage: 0.96 theta: -0.0890 theta_dot: -2.4027\n",
      "Epoch 14, Total Reward: -9.2884, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0373 alpha_dot: 1.9063 voltage: 1.31 theta: -0.1043 theta_dot: -2.6695\n",
      "Epoch 15, Total Reward: -9.1296, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0189 alpha_dot: 2.7974 voltage: 1.49 theta: -0.1227 theta_dot: -3.0201\n",
      "Epoch 16, Total Reward: -9.0271, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0035 alpha_dot: 3.1658 voltage: 1.60 theta: -0.1381 theta_dot: -3.1609\n",
      "Epoch 17, Total Reward: -9.0438, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9851 alpha_dot: 3.6405 voltage: 2.11 theta: -0.1565 theta_dot: -3.4223\n",
      "Epoch 18, Total Reward: -8.8223, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9667 alpha_dot: 3.9583 voltage: 1.91 theta: -0.1749 theta_dot: -3.6363\n",
      "Epoch 19, Total Reward: -8.7092, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9483 alpha_dot: 4.1711 voltage: 1.73 theta: -0.1963 theta_dot: -3.9437\n",
      "Epoch 20, Total Reward: -8.7490, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9299 alpha_dot: 4.3135 voltage: 2.30 theta: -0.2148 theta_dot: -4.0631\n",
      "Epoch 21, Total Reward: -8.5233, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9115 alpha_dot: 4.4089 voltage: 2.61 theta: -0.2332 theta_dot: -4.1608\n",
      "Epoch 22, Total Reward: -8.9614, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8962 alpha_dot: 4.1938 voltage: 1.53 theta: -0.2516 theta_dot: -4.2409\n",
      "Epoch 23, Total Reward: -8.3191, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8777 alpha_dot: 4.3287 voltage: 1.81 theta: -0.2700 theta_dot: -4.3064\n",
      "Epoch 24, Total Reward: -8.1986, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8624 alpha_dot: 4.1908 voltage: 1.71 theta: -0.2884 theta_dot: -4.3600\n",
      "Epoch 25, Total Reward: -8.3321, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8471 alpha_dot: 4.0478 voltage: 2.38 theta: -0.3068 theta_dot: -4.4039\n",
      "Epoch 26, Total Reward: -8.2266, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8317 alpha_dot: 3.9521 voltage: 1.73 theta: -0.3283 theta_dot: -4.5720\n",
      "Epoch 27, Total Reward: -8.0038, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8164 alpha_dot: 3.8880 voltage: 2.11 theta: -0.3467 theta_dot: -4.5774\n",
      "Epoch 28, Total Reward: -7.8623, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8010 alpha_dot: 3.8451 voltage: 2.30 theta: -0.3682 theta_dot: -4.7280\n",
      "Epoch 29, Total Reward: -7.8781, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7857 alpha_dot: 3.8164 voltage: 1.81 theta: -0.3866 theta_dot: -4.7051\n",
      "Epoch 30, Total Reward: -7.6750, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7704 alpha_dot: 3.8479 voltage: 1.81 theta: -0.4080 theta_dot: -4.8325\n",
      "Epoch 31, Total Reward: -7.7180, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7581 alpha_dot: 3.5901 voltage: 2.28 theta: -0.4264 theta_dot: -4.7907\n",
      "Epoch 32, Total Reward: -7.5680, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7428 alpha_dot: 3.6964 voltage: 2.59 theta: -0.4479 theta_dot: -4.8886\n",
      "Epoch 33, Total Reward: -7.5676, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7305 alpha_dot: 3.4886 voltage: 2.11 theta: -0.4694 theta_dot: -4.9827\n",
      "Epoch 34, Total Reward: -7.4054, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7213 alpha_dot: 3.1214 voltage: 2.12 theta: -0.4909 theta_dot: -5.0597\n",
      "Epoch 35, Total Reward: -7.3733, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7090 alpha_dot: 3.1037 voltage: 1.85 theta: -0.5093 theta_dot: -4.9767\n",
      "Epoch 36, Total Reward: -7.4216, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6967 alpha_dot: 3.0919 voltage: 2.40 theta: -0.5308 theta_dot: -5.0409\n",
      "Epoch 37, Total Reward: -7.2081, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6845 alpha_dot: 3.0840 voltage: 2.34 theta: -0.5522 theta_dot: -5.0934\n",
      "Epoch 38, Total Reward: -7.2472, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6753 alpha_dot: 2.8505 voltage: 1.92 theta: -0.5737 theta_dot: -5.1504\n",
      "Epoch 39, Total Reward: -7.1338, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6661 alpha_dot: 2.6942 voltage: 2.14 theta: -0.5952 theta_dot: -5.1970\n",
      "Epoch 40, Total Reward: -7.1347, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6569 alpha_dot: 2.5896 voltage: 1.75 theta: -0.6136 theta_dot: -5.0890\n",
      "Epoch 41, Total Reward: -7.0248, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6477 alpha_dot: 2.5195 voltage: 1.58 theta: -0.6351 theta_dot: -5.1328\n",
      "Epoch 42, Total Reward: -7.1703, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6415 alpha_dot: 2.1937 voltage: 2.20 theta: -0.6565 theta_dot: -5.1687\n",
      "Epoch 43, Total Reward: -7.1344, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6323 alpha_dot: 2.2038 voltage: 1.56 theta: -0.6842 theta_dot: -5.4624\n",
      "Epoch 44, Total Reward: -7.2174, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6262 alpha_dot: 1.9824 voltage: 2.36 theta: -0.7056 theta_dot: -5.4385\n",
      "Epoch 45, Total Reward: -6.9229, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6200 alpha_dot: 1.8342 voltage: 2.02 theta: -0.7271 theta_dot: -5.4189\n",
      "Epoch 46, Total Reward: -7.0112, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6170 alpha_dot: 1.4560 voltage: 1.45 theta: -0.7517 theta_dot: -5.5490\n",
      "Epoch 47, Total Reward: -7.2360, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6108 alpha_dot: 1.4818 voltage: 2.37 theta: -0.7731 theta_dot: -5.5233\n",
      "Epoch 48, Total Reward: -106.9796, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6078 alpha_dot: 1.2201 voltage: 1.77 theta: -0.7946 theta_dot: -5.4883\n",
      "Epoch 49, Total Reward: -107.0397, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6016 alpha_dot: 1.3239 voltage: 2.51 theta: -0.8191 theta_dot: -5.6058\n",
      "Epoch 50, Total Reward: -106.8301, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5986 alpha_dot: 1.1651 voltage: 2.11 theta: -0.8406 theta_dot: -5.5559\n",
      "Epoch 51, Total Reward: -106.7632, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5986 alpha_dot: 0.7800 voltage: 1.97 theta: -0.8652 theta_dot: -5.6611\n",
      "Epoch 52, Total Reward: -106.7638, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5955 alpha_dot: 0.7503 voltage: 2.20 theta: -0.8866 theta_dot: -5.6011\n",
      "Epoch 53, Total Reward: -106.7433, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5955 alpha_dot: 0.5023 voltage: 2.31 theta: -0.9112 theta_dot: -5.6982\n",
      "Epoch 54, Total Reward: -106.7370, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5955 alpha_dot: 0.3362 voltage: 2.34 theta: -0.9357 theta_dot: -5.7776\n",
      "Epoch 55, Total Reward: -106.9135, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5955 alpha_dot: 0.2251 voltage: 1.75 theta: -0.9572 theta_dot: -5.7104\n",
      "Epoch 56, Total Reward: -107.0288, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5955 alpha_dot: 0.1507 voltage: 2.51 theta: -0.9817 theta_dot: -5.7876\n",
      "Epoch 57, Total Reward: -106.8887, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5986 alpha_dot: -0.1273 voltage: 1.99 theta: -1.0063 theta_dot: -5.8508\n",
      "Epoch 58, Total Reward: -106.7883, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6016 alpha_dot: -0.3641 voltage: 1.79 theta: -1.0278 theta_dot: -5.7703\n",
      "Epoch 59, Total Reward: -106.8333, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6047 alpha_dot: -0.5227 voltage: 2.10 theta: -1.0523 theta_dot: -5.8366\n",
      "Epoch 60, Total Reward: -106.8806, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6078 alpha_dot: -0.5781 voltage: 1.70 theta: -1.0769 theta_dot: -5.8909\n",
      "Epoch 61, Total Reward: -106.8731, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6139 alpha_dot: -0.8941 voltage: 1.99 theta: -1.0983 theta_dot: -5.7893\n",
      "Epoch 62, Total Reward: -106.8673, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6200 alpha_dot: -1.1056 voltage: 2.06 theta: -1.1229 theta_dot: -5.8522\n",
      "Epoch 63, Total Reward: -107.0321, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6231 alpha_dot: -1.0190 voltage: 1.51 theta: -1.1474 theta_dot: -5.9036\n",
      "Epoch 64, Total Reward: -107.2179, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6323 alpha_dot: -1.4175 voltage: 2.27 theta: -1.1720 theta_dot: -5.9458\n",
      "Epoch 65, Total Reward: -107.0172, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6384 alpha_dot: -1.4560 voltage: 2.60 theta: -1.1965 theta_dot: -5.9803\n",
      "Epoch 66, Total Reward: -107.5794, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6446 alpha_dot: -1.4818 voltage: 1.52 theta: -1.2210 theta_dot: -6.0085\n",
      "Epoch 67, Total Reward: -107.4372, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6538 alpha_dot: -1.7272 voltage: 2.41 theta: -1.2456 theta_dot: -6.0316\n",
      "Epoch 68, Total Reward: -107.1289, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6630 alpha_dot: -1.8915 voltage: 2.14 theta: -1.2701 theta_dot: -6.0505\n",
      "Epoch 69, Total Reward: -107.1456, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6722 alpha_dot: -2.0015 voltage: 2.04 theta: -1.2947 theta_dot: -6.0660\n",
      "Epoch 70, Total Reward: -107.1616, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6753 alpha_dot: -1.5681 voltage: 1.94 theta: -1.3192 theta_dot: -6.0787\n",
      "Epoch 71, Total Reward: -107.2146, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6783 alpha_dot: -1.2779 voltage: 1.65 theta: -1.3438 theta_dot: -6.0891\n",
      "Epoch 72, Total Reward: -107.2282, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6875 alpha_dot: -1.6415 voltage: 1.76 theta: -1.3683 theta_dot: -6.0976\n",
      "Epoch 73, Total Reward: -107.4988, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6937 alpha_dot: -1.6059 voltage: 2.45 theta: -1.3929 theta_dot: -6.1045\n",
      "Epoch 74, Total Reward: -107.4052, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6998 alpha_dot: -1.6329 voltage: 1.97 theta: -1.4174 theta_dot: -6.1102\n",
      "Epoch 75, Total Reward: -107.4396, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7121 alpha_dot: -2.1073 voltage: 1.56 theta: -1.4450 theta_dot: -6.2610\n",
      "Epoch 76, Total Reward: -107.5669, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7243 alpha_dot: -2.4249 voltage: 2.10 theta: -1.4696 theta_dot: -6.2383\n",
      "Epoch 77, Total Reward: -107.4962, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7366 alpha_dot: -2.6375 voltage: 1.98 theta: -1.4972 theta_dot: -6.3658\n",
      "Epoch 78, Total Reward: -107.5595, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7489 alpha_dot: -2.7798 voltage: 1.90 theta: -1.5217 theta_dot: -6.3241\n",
      "Epoch 79, Total Reward: -107.6641, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7642 alpha_dot: -3.1539 voltage: 2.12 theta: -1.5493 theta_dot: -6.4222\n",
      "Epoch 80, Total Reward: -107.8050, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7765 alpha_dot: -3.1255 voltage: 1.68 theta: -1.5769 theta_dot: -6.5163\n",
      "Epoch 81, Total Reward: -107.9094, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7888 alpha_dot: -3.1065 voltage: 2.19 theta: -1.6045 theta_dot: -6.5934\n",
      "Epoch 82, Total Reward: -108.1064, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8041 alpha_dot: -3.3220 voltage: 1.50 theta: -1.6291 theta_dot: -6.5104\n",
      "Epoch 83, Total Reward: -107.9996, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8164 alpha_dot: -3.2380 voltage: 1.86 theta: -1.6567 theta_dot: -6.5747\n",
      "Epoch 84, Total Reward: -108.1072, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8317 alpha_dot: -3.4607 voltage: 2.28 theta: -1.6843 theta_dot: -6.6273\n",
      "Epoch 85, Total Reward: -108.0915, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8440 alpha_dot: -3.3309 voltage: 2.20 theta: -1.7150 theta_dot: -6.8164\n",
      "Epoch 86, Total Reward: -108.1807, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8593 alpha_dot: -3.5229 voltage: 2.30 theta: -1.7426 theta_dot: -6.8390\n",
      "Epoch 87, Total Reward: -108.2748, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8747 alpha_dot: -3.6514 voltage: 2.15 theta: -1.7702 theta_dot: -6.8576\n",
      "Epoch 88, Total Reward: -108.3363, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8870 alpha_dot: -3.4585 voltage: 2.09 theta: -1.7978 theta_dot: -6.8728\n",
      "Epoch 89, Total Reward: -108.4288, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9023 alpha_dot: -3.5576 voltage: 2.20 theta: -1.8254 theta_dot: -6.8713\n",
      "Epoch 90, Total Reward: -108.6492, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9176 alpha_dot: -3.6746 voltage: 2.72 theta: -1.8561 theta_dot: -7.0162\n",
      "Epoch 91, Total Reward: -109.0516, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9330 alpha_dot: -3.7530 voltage: 1.77 theta: -1.8837 theta_dot: -7.0026\n",
      "Epoch 92, Total Reward: -108.7907, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9452 alpha_dot: -3.5265 voltage: 2.26 theta: -1.9113 theta_dot: -6.9775\n",
      "Epoch 93, Total Reward: -108.9370, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9606 alpha_dot: -3.6031 voltage: 1.67 theta: -1.9420 theta_dot: -7.1031\n",
      "Epoch 94, Total Reward: -108.9549, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9759 alpha_dot: -3.7051 voltage: 2.11 theta: -1.9727 theta_dot: -7.2059\n",
      "Epoch 95, Total Reward: -108.9299, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9882 alpha_dot: -3.4945 voltage: 2.15 theta: -2.0003 theta_dot: -7.1440\n",
      "Epoch 96, Total Reward: -109.0239, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0035 alpha_dot: -3.5817 voltage: 2.07 theta: -2.0310 theta_dot: -7.2394\n",
      "Epoch 97, Total Reward: -109.2513, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0189 alpha_dot: -3.6908 voltage: 2.60 theta: -2.0617 theta_dot: -7.3175\n",
      "Epoch 98, Total Reward: -109.2813, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0311 alpha_dot: -3.4849 voltage: 2.17 theta: -2.0923 theta_dot: -7.3814\n",
      "Epoch 99, Total Reward: -109.3009, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0465 alpha_dot: -3.6260 voltage: 2.37 theta: -2.1230 theta_dot: -7.4338\n",
      "Epoch 100, Total Reward: -109.5220, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0588 alpha_dot: -3.4415 voltage: 1.79 theta: -2.1506 theta_dot: -7.3305\n",
      "Epoch 101, Total Reward: -109.4556, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0741 alpha_dot: -3.5462 voltage: 1.89 theta: -2.1813 theta_dot: -7.3921\n",
      "Epoch 102, Total Reward: -109.5840, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0894 alpha_dot: -3.6670 voltage: 2.18 theta: -2.2120 theta_dot: -7.4425\n",
      "Epoch 103, Total Reward: -109.8468, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1048 alpha_dot: -3.7479 voltage: 1.53 theta: -2.2427 theta_dot: -7.4837\n",
      "Epoch 104, Total Reward: -109.7715, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1170 alpha_dot: -3.5231 voltage: 1.86 theta: -2.2734 theta_dot: -7.5175\n",
      "Epoch 105, Total Reward: -109.8392, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1324 alpha_dot: -3.6516 voltage: 2.10 theta: -2.3040 theta_dot: -7.5452\n",
      "Epoch 106, Total Reward: -109.8298, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.1232 alpha_dot: 462.6433 voltage: 2.49 theta: -2.3040 theta_dot: -6.1625\n",
      "Epoch 107, Total Reward: -109.5245, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.0802 alpha_dot: 306.1537 voltage: 2.22 theta: -2.3071 theta_dot: -5.1768\n",
      "Epoch 108, Total Reward: -109.2129, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.0342 alpha_dot: 201.1172 voltage: 2.10 theta: -2.3040 theta_dot: -4.0916\n",
      "Epoch 109, Total Reward: -108.9518, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.9882 alpha_dot: 130.8036 voltage: 2.32 theta: -2.3040 theta_dot: -3.3493\n",
      "Epoch 110, Total Reward: -108.7581, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.9452 alpha_dot: 84.0637 voltage: 2.72 theta: -2.3040 theta_dot: -2.7418\n",
      "Epoch 111, Total Reward: -108.7375, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.9023 alpha_dot: 52.7751 voltage: 1.93 theta: -2.3071 theta_dot: -2.3905\n",
      "Epoch 112, Total Reward: -108.3730, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.8563 alpha_dot: 31.5509 voltage: 2.59 theta: -2.3071 theta_dot: -1.9568\n",
      "Epoch 113, Total Reward: -107.9261, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.8133 alpha_dot: 17.5711 voltage: 2.44 theta: -2.3071 theta_dot: -1.6018\n",
      "Epoch 114, Total Reward: -107.8792, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.7704 alpha_dot: 8.2128 voltage: 1.80 theta: -2.3071 theta_dot: -1.3113\n",
      "Epoch 115, Total Reward: -107.5426, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.7305 alpha_dot: 2.2270 voltage: 2.21 theta: -2.3071 theta_dot: -1.0734\n",
      "Epoch 116, Total Reward: -111.0670, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.6875 alpha_dot: -2.0589 voltage: -0.56 theta: -2.3071 theta_dot: -0.8787\n",
      "Epoch 117, Total Reward: -107.0253, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.6477 alpha_dot: -4.6998 voltage: -0.73 theta: -2.3071 theta_dot: -0.7193\n",
      "Epoch 118, Total Reward: -107.2139, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.6108 alpha_dot: -6.1887 voltage: 0.16 theta: -2.3071 theta_dot: -0.5888\n",
      "Epoch 119, Total Reward: -106.6387, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.5710 alpha_dot: -7.4137 voltage: 0.40 theta: -2.3071 theta_dot: -0.4820\n",
      "Epoch 120, Total Reward: -106.4226, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.5341 alpha_dot: -8.0055 voltage: 0.44 theta: -2.3071 theta_dot: -0.3945\n",
      "Epoch 121, Total Reward: -106.2529, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.5004 alpha_dot: -8.1227 voltage: 0.40 theta: -2.3071 theta_dot: -0.3230\n",
      "Epoch 122, Total Reward: -106.1228, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.4636 alpha_dot: -8.4801 voltage: 0.07 theta: -2.3071 theta_dot: -0.2644\n",
      "Epoch 123, Total Reward: -105.9211, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.4298 alpha_dot: -8.4912 voltage: -0.12 theta: -2.3071 theta_dot: -0.2164\n",
      "Epoch 124, Total Reward: -105.9284, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3991 alpha_dot: -8.2197 voltage: 0.47 theta: -2.3071 theta_dot: -0.1772\n",
      "Epoch 125, Total Reward: -105.9969, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3685 alpha_dot: -8.0379 voltage: -0.41 theta: -2.3071 theta_dot: -0.1450\n",
      "Epoch 126, Total Reward: -105.5941, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3409 alpha_dot: -7.6374 voltage: 0.07 theta: -2.3071 theta_dot: -0.1187\n",
      "Epoch 127, Total Reward: -105.4021, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3132 alpha_dot: -7.3692 voltage: 0.39 theta: -2.3071 theta_dot: -0.0972\n",
      "Epoch 128, Total Reward: -105.2542, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2856 alpha_dot: -7.1897 voltage: 0.14 theta: -2.3071 theta_dot: -0.0796\n",
      "Epoch 129, Total Reward: -105.2722, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2611 alpha_dot: -6.8414 voltage: -0.42 theta: -2.3071 theta_dot: -0.0651\n",
      "Epoch 130, Total Reward: -105.0183, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2396 alpha_dot: -6.3292 voltage: -0.35 theta: -2.3071 theta_dot: -0.0533\n",
      "Epoch 131, Total Reward: -104.9516, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2151 alpha_dot: -6.2653 voltage: -0.05 theta: -2.3071 theta_dot: -0.0436\n",
      "Epoch 132, Total Reward: -104.8322, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1967 alpha_dot: -5.7155 voltage: -0.17 theta: -2.3071 theta_dot: -0.0357\n",
      "Epoch 133, Total Reward: -104.9305, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1783 alpha_dot: -5.3474 voltage: -0.78 theta: -2.3071 theta_dot: -0.0292\n",
      "Epoch 134, Total Reward: -104.6981, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1598 alpha_dot: -5.1009 voltage: -0.52 theta: -2.3071 theta_dot: -0.0239\n",
      "Epoch 135, Total Reward: -104.6471, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1476 alpha_dot: -4.4289 voltage: -0.79 theta: -2.3071 theta_dot: -0.0196\n",
      "Epoch 136, Total Reward: -104.5465, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1322 alpha_dot: -4.2579 voltage: -0.80 theta: -2.3071 theta_dot: -0.0160\n",
      "Epoch 137, Total Reward: -104.6082, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1230 alpha_dot: -3.5856 voltage: -1.25 theta: -2.3071 theta_dot: -0.0131\n",
      "Epoch 138, Total Reward: -104.6257, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1108 alpha_dot: -3.4145 voltage: -0.66 theta: -2.3071 theta_dot: -0.0107\n",
      "Epoch 139, Total Reward: -104.6391, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1046 alpha_dot: -2.7928 voltage: -1.31 theta: -2.3071 theta_dot: -0.0088\n",
      "Epoch 140, Total Reward: -104.4144, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0954 alpha_dot: -2.6049 voltage: -1.09 theta: -2.3071 theta_dot: -0.0072\n",
      "Epoch 141, Total Reward: -104.7124, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0923 alpha_dot: -2.0227 voltage: -0.27 theta: -2.3071 theta_dot: -0.0059\n",
      "Epoch 142, Total Reward: -104.5428, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0893 alpha_dot: -1.5822 voltage: -0.87 theta: -2.3071 theta_dot: -0.0048\n",
      "Epoch 143, Total Reward: -104.5008, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0862 alpha_dot: -1.2874 voltage: -0.32 theta: -2.3071 theta_dot: -0.0040\n",
      "Epoch 144, Total Reward: -104.3845, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0862 alpha_dot: -0.8618 voltage: -0.58 theta: -2.3071 theta_dot: -0.0032\n",
      "Epoch 145, Total Reward: -104.3848, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0893 alpha_dot: -0.2980 voltage: -0.38 theta: -2.3071 theta_dot: -0.0026\n",
      "Epoch 146, Total Reward: -104.6670, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0923 alpha_dot: 0.0287 voltage: 0.38 theta: -2.3071 theta_dot: -0.0022\n",
      "Epoch 147, Total Reward: -104.4185, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.0985 alpha_dot: 0.5263 voltage: 0.55 theta: -2.3071 theta_dot: -0.0018\n",
      "Epoch 148, Total Reward: -104.5971, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1046 alpha_dot: 0.8594 voltage: 1.13 theta: -2.3071 theta_dot: -0.0015\n",
      "Epoch 149, Total Reward: -104.4826, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1138 alpha_dot: 1.3106 voltage: 1.30 theta: -2.3071 theta_dot: -0.0012\n",
      "Epoch 150, Total Reward: -104.5234, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1230 alpha_dot: 1.6127 voltage: 1.48 theta: -2.3071 theta_dot: -0.0010\n",
      "Epoch 151, Total Reward: -104.7194, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1353 alpha_dot: 2.0430 voltage: 2.05 theta: -2.3071 theta_dot: -0.0008\n",
      "Epoch 152, Total Reward: -104.6415, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1506 alpha_dot: 2.6101 voltage: 2.23 theta: -2.3071 theta_dot: -0.0007\n",
      "Epoch 153, Total Reward: -104.7200, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1660 alpha_dot: 2.9896 voltage: 1.99 theta: -2.3071 theta_dot: -0.0005\n",
      "Epoch 154, Total Reward: -104.7904, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.1844 alpha_dot: 3.5226 voltage: 2.18 theta: -2.3071 theta_dot: -0.0004\n",
      "Epoch 155, Total Reward: -104.8828, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2028 alpha_dot: 3.8794 voltage: 2.43 theta: -2.3071 theta_dot: -0.0004\n",
      "Epoch 156, Total Reward: -104.9770, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2212 alpha_dot: 4.1183 voltage: 2.14 theta: -2.3071 theta_dot: -0.0003\n",
      "Epoch 157, Total Reward: -105.1193, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2457 alpha_dot: 4.7853 voltage: 2.52 theta: -2.3071 theta_dot: -0.0002\n",
      "Epoch 158, Total Reward: -105.3040, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2672 alpha_dot: 5.0036 voltage: 1.95 theta: -2.3071 theta_dot: -0.0002\n",
      "Epoch 159, Total Reward: -105.2748, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.2948 alpha_dot: 5.6568 voltage: 2.08 theta: -2.3071 theta_dot: -0.0002\n",
      "Epoch 160, Total Reward: -105.3796, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3194 alpha_dot: 5.8152 voltage: 2.10 theta: -2.3071 theta_dot: -0.0001\n",
      "Epoch 161, Total Reward: -105.5091, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3470 alpha_dot: 6.1494 voltage: 2.13 theta: -2.3071 theta_dot: -0.0001\n",
      "Epoch 162, Total Reward: -105.6637, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.3777 alpha_dot: 6.6521 voltage: 1.99 theta: -2.3071 theta_dot: -0.0001\n",
      "Epoch 163, Total Reward: -105.9469, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.4083 alpha_dot: 6.9885 voltage: 2.53 theta: -2.3071 theta_dot: -0.0001\n",
      "Epoch 164, Total Reward: -105.9570, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.4390 alpha_dot: 7.2138 voltage: 2.66 theta: -2.3071 theta_dot: -0.0001\n",
      "Epoch 165, Total Reward: -106.1298, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.4758 alpha_dot: 7.8717 voltage: 2.66 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 166, Total Reward: -106.5153, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.5096 alpha_dot: 8.0839 voltage: 2.00 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 167, Total Reward: -106.5403, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.5464 alpha_dot: 8.4541 voltage: 2.33 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 168, Total Reward: -106.7140, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.5832 alpha_dot: 8.7527 voltage: 2.62 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 169, Total Reward: -106.9014, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.6200 alpha_dot: 8.9018 voltage: 2.35 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 170, Total Reward: -107.0834, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.6599 alpha_dot: 9.2806 voltage: 2.48 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 171, Total Reward: -107.3317, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.6998 alpha_dot: 9.5341 voltage: 2.18 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 172, Total Reward: -107.5697, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.7397 alpha_dot: 9.6532 voltage: 2.54 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 173, Total Reward: -107.7458, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.7826 alpha_dot: 10.0117 voltage: 2.47 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 174, Total Reward: -108.0028, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.8256 alpha_dot: 10.2518 voltage: 2.66 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 175, Total Reward: -108.2528, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.8685 alpha_dot: 10.4125 voltage: 2.44 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 176, Total Reward: -108.5073, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.9115 alpha_dot: 10.5200 voltage: 2.20 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 177, Total Reward: -108.7470, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 2.9575 alpha_dot: 10.8710 voltage: 2.21 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 178, Total Reward: -109.0305, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.0005 alpha_dot: 10.8270 voltage: 2.44 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 179, Total Reward: -109.2813, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.0465 alpha_dot: 11.0257 voltage: 2.42 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 180, Total Reward: -109.7710, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.0925 alpha_dot: 11.2095 voltage: 3.06 theta: -2.3071 theta_dot: -0.0000\n",
      "Epoch 181, Total Reward: -110.0548, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: 3.1355 alpha_dot: 11.0536 voltage: 2.40 theta: -2.3040 theta_dot: 0.1322\n",
      "Epoch 182, Total Reward: -109.6585, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.1017 alpha_dot: -456.1670 voltage: 2.12 theta: -2.3040 theta_dot: 0.1082\n",
      "Epoch 183, Total Reward: -109.4180, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0588 alpha_dot: -301.8183 voltage: 2.47 theta: -2.3010 theta_dot: 0.2347\n",
      "Epoch 184, Total Reward: -109.2090, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -3.0158 alpha_dot: -198.4939 voltage: 2.95 theta: -2.2979 theta_dot: 0.3382\n",
      "Epoch 185, Total Reward: -108.9208, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9729 alpha_dot: -129.3264 voltage: 2.54 theta: -2.2948 theta_dot: 0.4229\n",
      "Epoch 186, Total Reward: -108.6086, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.9330 alpha_dot: -83.3031 voltage: 2.43 theta: -2.2887 theta_dot: 0.6245\n",
      "Epoch 187, Total Reward: -108.3882, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8931 alpha_dot: -52.4941 voltage: 2.24 theta: -2.2856 theta_dot: 0.6573\n",
      "Epoch 188, Total Reward: -108.2429, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8563 alpha_dot: -32.0980 voltage: 1.83 theta: -2.2764 theta_dot: 0.9485\n",
      "Epoch 189, Total Reward: -108.4992, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8225 alpha_dot: -18.7234 voltage: 2.86 theta: -2.2672 theta_dot: 1.2008\n",
      "Epoch 190, Total Reward: -109.4290, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7888 alpha_dot: -9.7194 voltage: 1.04 theta: -2.2580 theta_dot: 1.4073\n",
      "Epoch 191, Total Reward: -107.6136, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7581 alpha_dot: -3.9709 voltage: 1.16 theta: -2.2488 theta_dot: 1.5764\n",
      "Epoch 192, Total Reward: -107.4472, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7274 alpha_dot: -0.1227 voltage: 1.29 theta: -2.2365 theta_dot: 1.8470\n",
      "Epoch 193, Total Reward: -107.2939, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6998 alpha_dot: 2.2252 voltage: 1.19 theta: -2.2243 theta_dot: 2.0685\n",
      "Epoch 194, Total Reward: -107.3193, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6753 alpha_dot: 3.5180 voltage: 1.76 theta: -2.2089 theta_dot: 2.3820\n",
      "Epoch 195, Total Reward: -107.0285, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6507 alpha_dot: 4.3834 voltage: 1.82 theta: -2.1936 theta_dot: 2.6386\n",
      "Epoch 196, Total Reward: -106.8990, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6262 alpha_dot: 4.9628 voltage: 1.89 theta: -2.1752 theta_dot: 2.9948\n",
      "Epoch 197, Total Reward: -106.8385, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6078 alpha_dot: 4.8435 voltage: 1.61 theta: -2.1598 theta_dot: 3.1541\n",
      "Epoch 198, Total Reward: -106.7549, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5894 alpha_dot: 4.7636 voltage: 1.30 theta: -2.1414 theta_dot: 3.4168\n",
      "Epoch 199, Total Reward: -106.8126, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5710 alpha_dot: 4.7102 voltage: 1.93 theta: -2.1200 theta_dot: 3.7639\n",
      "Epoch 200, Total Reward: -106.5468, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5556 alpha_dot: 4.4462 voltage: 1.76 theta: -2.0985 theta_dot: 4.0621\n",
      "Epoch 201, Total Reward: -106.4604, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5403 alpha_dot: 4.2695 voltage: 1.88 theta: -2.0770 theta_dot: 4.3061\n",
      "Epoch 202, Total Reward: -106.4800, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5249 alpha_dot: 4.1512 voltage: 1.42 theta: -2.0555 theta_dot: 4.5059\n",
      "Epoch 203, Total Reward: -106.6273, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5127 alpha_dot: 3.8438 voltage: 2.21 theta: -2.0279 theta_dot: 4.9616\n",
      "Epoch 204, Total Reward: -106.5627, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5004 alpha_dot: 3.5873 voltage: 1.42 theta: -2.0034 theta_dot: 5.1746\n",
      "Epoch 205, Total Reward: -106.6674, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4943 alpha_dot: 2.9085 voltage: 2.37 theta: -1.9819 theta_dot: 5.2168\n",
      "Epoch 206, Total Reward: -106.1986, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4881 alpha_dot: 2.4541 voltage: 2.24 theta: -1.9574 theta_dot: 5.3835\n",
      "Epoch 207, Total Reward: -106.1658, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4789 alpha_dot: 2.4289 voltage: 2.04 theta: -1.9328 theta_dot: 5.5200\n",
      "Epoch 208, Total Reward: -106.1594, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4758 alpha_dot: 1.9048 voltage: 1.80 theta: -1.9052 theta_dot: 5.7639\n",
      "Epoch 209, Total Reward: -106.4786, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4728 alpha_dot: 1.5033 voltage: 2.65 theta: -1.8807 theta_dot: 5.8314\n",
      "Epoch 210, Total Reward: -106.2239, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4697 alpha_dot: 1.2853 voltage: 2.15 theta: -1.8530 theta_dot: 6.0327\n",
      "Epoch 211, Total Reward: -106.1006, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4697 alpha_dot: 0.8604 voltage: 2.10 theta: -1.8285 theta_dot: 6.0515\n",
      "Epoch 212, Total Reward: -106.1135, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4666 alpha_dot: 0.8042 voltage: 2.34 theta: -1.8009 theta_dot: 6.2129\n",
      "Epoch 213, Total Reward: -106.2832, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4666 alpha_dot: 0.5383 voltage: 1.71 theta: -1.7763 theta_dot: 6.1989\n",
      "Epoch 214, Total Reward: -106.3967, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4697 alpha_dot: 0.1322 voltage: 2.48 theta: -1.7487 theta_dot: 6.3197\n",
      "Epoch 215, Total Reward: -106.1399, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4728 alpha_dot: -0.1904 voltage: 2.26 theta: -1.7211 theta_dot: 6.4324\n",
      "Epoch 216, Total Reward: -106.1504, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4728 alpha_dot: -0.1275 voltage: 2.53 theta: -1.6966 theta_dot: 6.3786\n",
      "Epoch 217, Total Reward: -106.3516, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4758 alpha_dot: -0.3135 voltage: 1.86 theta: -1.6690 theta_dot: 6.4807\n",
      "Epoch 218, Total Reward: -106.1637, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4820 alpha_dot: -0.7170 voltage: 1.78 theta: -1.6444 theta_dot: 6.4182\n",
      "Epoch 219, Total Reward: -106.2852, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4850 alpha_dot: -0.7589 voltage: 2.25 theta: -1.6199 theta_dot: 6.3670\n",
      "Epoch 220, Total Reward: -106.2005, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4881 alpha_dot: -0.7362 voltage: 2.11 theta: -1.5953 theta_dot: 6.3250\n",
      "Epoch 221, Total Reward: -106.2238, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.4943 alpha_dot: -0.9999 voltage: 2.18 theta: -1.5708 theta_dot: 6.2907\n",
      "Epoch 222, Total Reward: -106.2556, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5004 alpha_dot: -1.1765 voltage: 2.26 theta: -1.5463 theta_dot: 6.2627\n",
      "Epoch 223, Total Reward: -106.2897, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5065 alpha_dot: -1.2947 voltage: 2.38 theta: -1.5217 theta_dot: 6.2397\n",
      "Epoch 224, Total Reward: -106.3838, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5127 alpha_dot: -1.3738 voltage: 2.01 theta: -1.5002 theta_dot: 6.0887\n",
      "Epoch 225, Total Reward: -106.4995, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5219 alpha_dot: -1.7056 voltage: 1.48 theta: -1.4788 theta_dot: 5.9511\n",
      "Epoch 226, Total Reward: -106.5531, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5280 alpha_dot: -1.6489 voltage: 2.05 theta: -1.4542 theta_dot: 5.9847\n",
      "Epoch 227, Total Reward: -106.4441, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5372 alpha_dot: -1.8898 voltage: 2.16 theta: -1.4327 theta_dot: 5.8799\n",
      "Epoch 228, Total Reward: -106.5430, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5433 alpha_dot: -1.7722 voltage: 1.78 theta: -1.4113 theta_dot: 5.7942\n",
      "Epoch 229, Total Reward: -106.5192, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5525 alpha_dot: -1.9216 voltage: 1.86 theta: -1.3898 theta_dot: 5.7240\n",
      "Epoch 230, Total Reward: -106.5756, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5617 alpha_dot: -2.0217 voltage: 1.70 theta: -1.3714 theta_dot: 5.5205\n",
      "Epoch 231, Total Reward: -106.6887, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5710 alpha_dot: -2.0887 voltage: 2.10 theta: -1.3499 theta_dot: 5.4860\n",
      "Epoch 232, Total Reward: -106.6849, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5832 alpha_dot: -2.4124 voltage: 1.94 theta: -1.3315 theta_dot: 5.3256\n",
      "Epoch 233, Total Reward: -106.7315, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.5924 alpha_dot: -2.4009 voltage: 2.09 theta: -1.3100 theta_dot: 5.3404\n",
      "Epoch 234, Total Reward: -107.1529, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6047 alpha_dot: -2.6214 voltage: 1.23 theta: -1.2916 theta_dot: 5.2065\n",
      "Epoch 235, Total Reward: -106.9223, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6139 alpha_dot: -2.4901 voltage: 1.66 theta: -1.2732 theta_dot: 5.0968\n",
      "Epoch 236, Total Reward: -107.0072, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6262 alpha_dot: -2.6812 voltage: 2.13 theta: -1.2579 theta_dot: 4.8749\n",
      "Epoch 237, Total Reward: -106.9635, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6384 alpha_dot: -2.8090 voltage: 2.06 theta: -1.2395 theta_dot: 4.8253\n",
      "Epoch 238, Total Reward: -107.0866, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6507 alpha_dot: -2.8946 voltage: 2.41 theta: -1.2241 theta_dot: 4.6387\n",
      "Epoch 239, Total Reward: -107.2317, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6630 alpha_dot: -2.9519 voltage: 1.88 theta: -1.2088 theta_dot: 4.4860\n",
      "Epoch 240, Total Reward: -107.1581, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6753 alpha_dot: -2.9903 voltage: 1.93 theta: -1.1934 theta_dot: 4.3609\n",
      "Epoch 241, Total Reward: -107.3016, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6875 alpha_dot: -3.0160 voltage: 1.53 theta: -1.1781 theta_dot: 4.2585\n",
      "Epoch 242, Total Reward: -107.3961, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.6998 alpha_dot: -3.0332 voltage: 1.99 theta: -1.1628 theta_dot: 4.1887\n",
      "Epoch 243, Total Reward: -107.6164, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7121 alpha_dot: -3.0447 voltage: 1.27 theta: -1.1505 theta_dot: 3.9854\n",
      "Epoch 244, Total Reward: -107.7349, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7243 alpha_dot: -3.0524 voltage: 2.06 theta: -1.1382 theta_dot: 3.8189\n",
      "Epoch 245, Total Reward: -107.4931, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7366 alpha_dot: -3.0575 voltage: 1.97 theta: -1.1259 theta_dot: 3.6827\n",
      "Epoch 246, Total Reward: -107.9940, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7489 alpha_dot: -3.0610 voltage: 1.04 theta: -1.1167 theta_dot: 3.4251\n",
      "Epoch 247, Total Reward: -107.8660, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7612 alpha_dot: -3.0633 voltage: 1.73 theta: -1.1045 theta_dot: 3.3603\n",
      "Epoch 248, Total Reward: -107.7656, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7734 alpha_dot: -3.0648 voltage: 1.35 theta: -1.0953 theta_dot: 3.1612\n",
      "Epoch 249, Total Reward: -107.8232, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7857 alpha_dot: -3.0659 voltage: 1.70 theta: -1.0861 theta_dot: 2.9982\n",
      "Epoch 250, Total Reward: -107.8740, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.7980 alpha_dot: -3.0666 voltage: 1.40 theta: -1.0769 theta_dot: 2.8787\n",
      "Epoch 251, Total Reward: -107.8811, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8072 alpha_dot: -2.7881 voltage: 1.36 theta: -1.0707 theta_dot: 2.6347\n",
      "Epoch 252, Total Reward: -107.9519, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8195 alpha_dot: -2.8806 voltage: 1.29 theta: -1.0646 theta_dot: 2.4350\n",
      "Epoch 253, Total Reward: -108.1613, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8287 alpha_dot: -2.6637 voltage: 1.86 theta: -1.0584 theta_dot: 2.2716\n",
      "Epoch 254, Total Reward: -108.1804, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8409 alpha_dot: -2.7973 voltage: 1.39 theta: -1.0554 theta_dot: 2.0056\n",
      "Epoch 255, Total Reward: -108.1861, Q1: 0.0000, Q2: 0.0000, TargetQ: 0.0000 alpha: -2.8501 alpha_dot: -2.6586 voltage: 1.74 theta: -1.0523 theta_dot: 1.7740\n",
      "Epoch 256, Total Reward: -108.1866, Q1: 0.2204, Q2: 3.4047, TargetQ: -88.7373 alpha: -2.8593 alpha_dot: -2.5657 voltage: 2.14 theta: -1.0492 theta_dot: 1.5982\n",
      "Epoch 257, Total Reward: -108.2539, Q1: 0.2202, Q2: 3.3953, TargetQ: -88.7431 alpha: -2.8685 alpha_dot: -2.5036 voltage: 1.37 theta: -1.0492 theta_dot: 1.3083\n",
      "Epoch 258, Total Reward: -108.2710, Q1: 0.2171, Q2: 3.3815, TargetQ: -88.7332 alpha: -2.8747 alpha_dot: -2.1830 voltage: 2.11 theta: -1.0492 theta_dot: 1.0710\n",
      "Epoch 259, Total Reward: -108.3369, Q1: 0.2033, Q2: 3.2735, TargetQ: -89.5172 alpha: -2.8808 alpha_dot: -1.9685 voltage: 1.77 theta: -1.0492 theta_dot: 0.8767\n",
      "Epoch 260, Total Reward: -108.8359, Q1: 0.2141, Q2: 3.3397, TargetQ: -88.7639 alpha: -2.9606 alpha_dot: -8.5186 voltage: -0.54 theta: -1.1934 theta_dot: -6.1348\n",
      "Epoch 261, Total Reward: -108.0510, Q1: 0.2125, Q2: 3.3450, TargetQ: -89.1704 alpha: -2.8225 alpha_dot: 6.8989 voltage: 2.55 theta: -2.0647 theta_dot: -46.4290\n",
      "Epoch 262, Total Reward: -108.1270, Q1: 0.1783, Q2: 3.6104, TargetQ: -88.7933 alpha: 2.8471 alpha_dot: 519.9851 voltage: 1.99 theta: -2.2089 theta_dot: -44.7477\n",
      "Epoch 263, Total Reward: -107.0961, Q1: 0.1336, Q2: 3.6175, TargetQ: -89.1966 alpha: 2.6507 alpha_dot: 330.6449 voltage: 2.72 theta: -2.3102 theta_dot: -41.4512\n",
      "Epoch 264, Total Reward: -108.8312, Q1: 0.1718, Q2: 3.8786, TargetQ: -89.5416 alpha: -2.9575 alpha_dot: -288.8029 voltage: 2.08 theta: -2.3102 theta_dot: -33.9317\n",
      "Epoch 265, Total Reward: -107.3937, Q1: 0.1809, Q2: 3.9175, TargetQ: -90.3250 alpha: -2.6722 alpha_dot: -167.7983 voltage: 3.02 theta: -2.1292 theta_dot: -19.1568\n",
      "Epoch 266, Total Reward: -109.8214, Q1: 0.1650, Q2: 3.7936, TargetQ: -90.7225 alpha: 3.1170 alpha_dot: 414.3728 voltage: 2.12 theta: -1.9052 theta_dot: -5.0725\n",
      "Epoch 267, Total Reward: -109.3906, Q1: 0.1699, Q2: 4.2088, TargetQ: -88.8017 alpha: -3.0618 alpha_dot: -284.0216 voltage: 2.74 theta: -2.3010 theta_dot: -23.0123\n",
      "Epoch 268, Total Reward: -110.1381, Q1: 0.1279, Q2: 4.2385, TargetQ: -89.9413 alpha: 3.1385 alpha_dot: 373.6902 voltage: 2.13 theta: -2.2948 theta_dot: -18.5594\n",
      "Epoch 269, Total Reward: -109.9417, Q1: 0.1407, Q2: 4.1623, TargetQ: -89.9521 alpha: 3.1232 alpha_dot: 352.5146 voltage: 2.59 theta: -2.3132 theta_dot: -16.0414\n",
      "Epoch 270, Total Reward: -109.7166, Q1: 0.1234, Q2: 4.5406, TargetQ: -89.1325 alpha: -3.1048 alpha_dot: -330.1975 voltage: 2.50 theta: -2.3132 theta_dot: -13.1314\n",
      "Epoch 271, Total Reward: -109.2312, Q1: 0.0928, Q2: 4.2854, TargetQ: -90.3316 alpha: -3.0342 alpha_dot: -214.6772 voltage: 2.42 theta: -2.3132 theta_dot: -10.7493\n",
      "Epoch 272, Total Reward: -109.3685, Q1: 0.1123, Q2: 4.3775, TargetQ: -89.1777 alpha: -3.0557 alpha_dot: -145.6619 voltage: 2.07 theta: -2.3132 theta_dot: -8.7993\n",
      "Epoch 273, Total Reward: -109.8732, Q1: 0.0803, Q2: 4.6146, TargetQ: -91.5059 alpha: 3.1355 alpha_dot: 465.3223 voltage: 2.96 theta: -2.3132 theta_dot: -7.2030\n",
      "Epoch 274, Total Reward: -110.1096, Q1: 0.1202, Q2: 4.2723, TargetQ: -90.7120 alpha: -3.1385 alpha_dot: -258.8145 voltage: -0.21 theta: -2.3132 theta_dot: -5.8964\n",
      "Epoch 275, Total Reward: -109.2547, Q1: 0.0955, Q2: 4.4801, TargetQ: -89.9574 alpha: -3.0403 alpha_dot: -164.3817 voltage: 2.10 theta: -2.3132 theta_dot: -4.8267\n",
      "Epoch 276, Total Reward: -109.3864, Q1: 0.0942, Q2: 4.6008, TargetQ: -89.1945 alpha: -3.0465 alpha_dot: -110.5985 voltage: 2.49 theta: -2.3132 theta_dot: -3.9511\n",
      "Epoch 277, Total Reward: -109.8961, Q1: 0.0844, Q2: 4.4822, TargetQ: -90.0027 alpha: -3.1385 alpha_dot: -82.3534 voltage: 2.86 theta: -2.3132 theta_dot: -3.2344\n",
      "Epoch 278, Total Reward: -109.7558, Q1: 0.0232, Q2: 4.3231, TargetQ: -90.7252 alpha: 3.1232 alpha_dot: 514.1172 voltage: 1.89 theta: -2.3132 theta_dot: -2.6476\n",
      "Epoch 279, Total Reward: -109.5363, Q1: -0.0140, Q2: 4.1698, TargetQ: -90.0305 alpha: -3.0833 alpha_dot: -220.1157 voltage: 2.56 theta: -2.3132 theta_dot: -2.1673\n",
      "Epoch 280, Total Reward: -109.3253, Q1: 0.0844, Q2: 3.9229, TargetQ: -89.5352 alpha: -3.0403 alpha_dot: -143.4962 voltage: 1.72 theta: -2.3132 theta_dot: -1.7742\n",
      "Epoch 281, Total Reward: -110.1155, Q1: 0.0888, Q2: 3.7347, TargetQ: -89.5701 alpha: -3.1078 alpha_dot: -102.2461 voltage: 3.11 theta: -2.3132 theta_dot: -1.4523\n",
      "Epoch 282, Total Reward: -109.8969, Q1: -0.0458, Q2: 4.1252, TargetQ: -91.2463 alpha: 3.1293 alpha_dot: 498.6201 voltage: 2.11 theta: -2.3132 theta_dot: -1.1889\n",
      "Epoch 283, Total Reward: -109.6058, Q1: -0.0017, Q2: 3.6630, TargetQ: -89.9747 alpha: -3.0986 alpha_dot: -232.3407 voltage: 2.56 theta: -2.3132 theta_dot: -0.9732\n",
      "Epoch 284, Total Reward: -109.3349, Q1: -0.0229, Q2: 3.6758, TargetQ: -90.8034 alpha: -3.0465 alpha_dot: -150.8431 voltage: 1.70 theta: -2.3132 theta_dot: -0.7967\n",
      "Epoch 285, Total Reward: -109.4482, Q1: -0.0700, Q2: 3.3482, TargetQ: -90.0546 alpha: -3.0618 alpha_dot: -102.3722 voltage: 2.62 theta: -2.3132 theta_dot: -0.6521\n",
      "\n",
      "Stopping (Ctrl+C). Saving\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "history = []\n",
    "policy_delay = 2  # Delayed policy updates\n",
    "step = 0\n",
    "total_reward = 0.0\n",
    "frequency = 500  # Hz\n",
    "state_theta_dot = np.array([0,0], dtype=np.float64)\n",
    "state_alpha_dot = np.array([0,0], dtype=np.float64)\n",
    "\n",
    "prev_action = np.zeros(action_size, dtype=np.float32)\n",
    "avg_q = []\n",
    "step_in_episode = 0\n",
    "\n",
    "try: \n",
    "    with QubeServo3(hardware = 1, pendulum = 1, frequency=500) as board:\n",
    "        while True:\n",
    "            board.read_outputs()\n",
    "            theta = board.motorPosition * -1\n",
    "            alpha = board.pendulumPosition \n",
    "            alpha = np.mod(alpha, 2*np.pi) - np.pi\n",
    "            theta_dot, state_theta_dot = ddt_filter(theta, state_theta_dot, 50, 1/frequency)\n",
    "            alpha_dot, state_alpha_dot = ddt_filter(alpha, state_alpha_dot, 100, 1/frequency)\n",
    "            state = np.array([theta, theta_dot, alpha, alpha_dot], dtype=np.float32)\n",
    "\n",
    "            for _ in range(1): # steps per control action\n",
    "                avg_q1, avg_q2, avg_target_q = 0.0, 0.0, 0.0\n",
    "                step += 1 \n",
    "                \n",
    "                action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "                action = action + np.random.normal(0, 0.3, size=action_size)  # Add exploration noise\n",
    "                board.write_voltage(action)\n",
    "                \n",
    "                # scopeVoltage.sample(timeStamp, np.array(action).reshape(-1)[0])\n",
    "\n",
    "                board.read_outputs()\n",
    "                next_theta = board.motorPosition * -1\n",
    "                next_alpha = board.pendulumPosition\n",
    "                next_alpha = np.mod(next_alpha, 2*np.pi) - np.pi\n",
    "                next_theta_dot, state_theta_dot = ddt_filter(next_theta, state_theta_dot, 50, 1/frequency)\n",
    "                next_alpha_dot, state_alpha_dot = ddt_filter(next_alpha, state_alpha_dot, 100, 1/frequency)\n",
    "                next_state = np.array([next_theta, next_theta_dot, next_alpha, next_alpha_dot], dtype=np.float32)\n",
    "                \n",
    "                if np.abs(theta) > np.pi/4:\n",
    "                    pen = 100\n",
    "                else:\n",
    "                    pen = 0\n",
    "\n",
    "                delta_u = action - prev_action\n",
    "                reward = -((\n",
    "                    alpha**2 +\n",
    "                    0.5 * delta_u**2\n",
    "                ))\n",
    "                prev_action = action.copy()\n",
    "                reward = float(reward - pen) \n",
    "                total_reward += reward\n",
    "\n",
    "                replay_buffer.store(state, action, reward, next_state, False)\n",
    "                state = next_state\n",
    "\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "                states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "                actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
    "                rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "                next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "                dones = tf.convert_to_tensor(dones, dtype=tf.float32) \n",
    "\n",
    "                # add clipped noise to target action\n",
    "                noise = tf.random.normal(shape=tf.shape(actions), mean=0.0, stddev=0.3, dtype=tf.float32)\n",
    "                next_actions = target_actor(next_states) + noise\n",
    "                next_actions = tf.clip_by_value(next_actions, -2.0, 2.0)\n",
    "\n",
    "                # Compute target Q-values with both critics\n",
    "                target1 = tf.squeeze(target_critic1([next_states, next_actions]), axis=1)\n",
    "                target2 = tf.squeeze(target_critic2([next_states, next_actions]), axis=1)\n",
    "                target_q = rewards + gamma * (1 - dones) * tf.minimum(target1, target2)\n",
    "                # target_q = tf.clip_by_value(target_q, 0, 1e8)\n",
    "                target_q = tf.expand_dims(target_q, axis=1)  # shape (batch,1)\n",
    "                \n",
    "                with tf.GradientTape() as tape_critic1, tf.GradientTape() as tape_critic2:\n",
    "                    q1 = critic_model1([states, actions], training=True)\n",
    "                    q2 = critic_model2([states, actions], training=True)\n",
    "\n",
    "                    # Compute losses\n",
    "                    loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "                    loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "\n",
    "                avg_q1 = tf.reduce_mean(q1).numpy().item()\n",
    "                avg_q2 = tf.reduce_mean(q2).numpy().item()\n",
    "                avg_target_q = tf.reduce_mean(target_q).numpy().item()\n",
    "\n",
    "                # Get gradients for each critic once\n",
    "                critic_grad1 = tape_critic1.gradient(loss1, critic_model1.trainable_variables)\n",
    "                critic_grad2 = tape_critic2.gradient(loss2, critic_model2.trainable_variables)\n",
    "\n",
    "                # Apply gradients\n",
    "                critic_optimizer1.apply_gradients(zip(critic_grad1, critic_model1.trainable_variables))\n",
    "                critic_optimizer2.apply_gradients(zip(critic_grad2, critic_model2.trainable_variables))\n",
    "                if step % policy_delay == 0:  # Delayed policy updates\n",
    "                    with tf.GradientTape() as tape_actor: \n",
    "                        action = actor_model(states)\n",
    "                        actor_loss = -tf.reduce_mean(critic_model1([states, action]))\n",
    "\n",
    "                    actor_grad = tape_actor.gradient(actor_loss, actor_model.trainable_variables)\n",
    "                    actor_optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "\n",
    "                    soft_update(target_actor.variables, actor_model.variables, tau=0.005)\n",
    "                    soft_update(target_critic1.variables, critic_model1.variables, tau=0.005)\n",
    "                    soft_update(target_critic2.variables, critic_model2.variables, tau=0.005)\n",
    "\n",
    "            history.append(total_reward)\n",
    "            if step % 1 == 0:\n",
    "                avg_q.append(avg_target_q)\n",
    "                print(f\"Epoch {step}, Total Reward: {float(reward):.4f}, \"\n",
    "                f\"Q1: {avg_q1:.4f}, Q2: {avg_q2:.4f}, TargetQ: {avg_target_q:.4f}\", \n",
    "                f\"alpha: {alpha:.4f}\", f\"alpha_dot: {alpha_dot:.4f}\", \n",
    "                f\"voltage: {np.array(action).reshape(-1)[0]:.2f}\", \n",
    "                f\"theta: {theta:.4f}\", f\"theta_dot: {theta_dot:.4f}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping (Ctrl+C). Saving\")\n",
    "finally:\n",
    "    actor_model.save_weights(\"saves/quanser/actor_model.weights.h5\")\n",
    "    critic_model1.save_weights(\"saves/quanser/critic_model1.weights.h5\")\n",
    "    critic_model2.save_weights(\"saves/quanser/critic_model2.weights.h5\")\n",
    "    ckpt = tf.train.Checkpoint(actor_optimizer=actor_optimizer,\n",
    "                           critic_optimizer1=critic_optimizer1,\n",
    "                           critic_optimizer2=critic_optimizer2)\n",
    "    ckpt.save(\"saves/quanser/optimizers_ckpt/ckpt\")\n",
    "    plt.title(\"Average Target Q over Time\")\n",
    "    plt.plot(avg_q, label='Target Q')\n",
    "    plt.legend()\n",
    "    print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
