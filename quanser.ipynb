{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8ceea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.layers import Concatenate\n",
    "from collections import deque\n",
    "import random\n",
    "from quanser.hardware import HIL \n",
    "from pal.products.qube import QubeServo3\n",
    "from pal.utilities.math import SignalGenerator, ddt_filter\n",
    "from threading import Thread\n",
    "import time\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8674aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # board.close()\n",
    "# # Open connection to QUBE\n",
    "# # board = HIL(\"qube_servo3_usb\", \"0\")\n",
    "\n",
    "# encoder_channels = np.array([0, 1], dtype=np.uint32)\n",
    "# motor_channels = np.array([0], dtype=np.uint32)\n",
    "# counts = np.zeros(2, dtype=np.int32)\n",
    "\n",
    "# ENCODER_RES = 2048\n",
    "# ARM_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "# PEND_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "\n",
    "# dt = 0.01  # 10 ms\n",
    "# theta_arm_prev  = counts[0] * ARM_RAD_PER_COUNT\n",
    "# theta_pend_prev = counts[1] * PEND_RAD_PER_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49e7c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "global KILL_THREAD\n",
    "KILL_THREAD = False\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
    "        return (np.array(states, dtype=np.float32),\n",
    "            np.array(actions, dtype=np.float32),\n",
    "            np.array(rewards, dtype=np.float32),\n",
    "            np.array(next_states, dtype=np.float32),\n",
    "            np.array(dones, dtype=np.float32))\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "def soft_update(target_weights, online_weights, tau=0.005):\n",
    "    for (target, online) in zip(target_weights, online_weights):\n",
    "        target.assign(target * (1 - tau) + online * tau) \n",
    "\n",
    "def sig_handler(*args): \n",
    "    global KILL_THREAD\n",
    "    KILL_THREAD = True\n",
    "\n",
    "signal.signal(signal.SIGINT, sig_handler)\n",
    "\n",
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8509c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x26821244700>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size = 4\n",
    "action_size = 1\n",
    "gamma = 0.99 # discount rate\n",
    "learning_rate = 0.001 # learning rate\n",
    "\n",
    "# Define the actor model\n",
    "states_inputs = Input(shape=(state_size,))\n",
    "dense = Dense(128, activation='tanh')(states_inputs)\n",
    "dense = Dense(128, activation='tanh')(dense)\n",
    "outputs = Dense(action_size, activation='tanh')(dense)\n",
    "outputs = keras.layers.Lambda(lambda x: x * 3)(outputs)  \n",
    "actor_model = Model(inputs=states_inputs, outputs=outputs)\n",
    "\n",
    "# Critic 1\n",
    "state_input1 = Input(shape=(state_size,))\n",
    "action_input1 = Input(shape=(action_size,))\n",
    "concat1 = Concatenate()([state_input1, action_input1])\n",
    "dense1 = Dense(128, activation='tanh')(concat1)\n",
    "dense1 = Dense(128, activation='tanh')(dense1)\n",
    "sigmoid_layer = Dense(1, activation='tanh')(dense1)\n",
    "output1 = Dense(1)(sigmoid_layer)\n",
    "critic_model1 = Model([state_input1, action_input1], output1)\n",
    "\n",
    "# Critic 2\n",
    "state_input2 = Input(shape=(state_size,))\n",
    "action_input2 = Input(shape=(action_size,))\n",
    "concat2 = Concatenate()([state_input2, action_input2])\n",
    "dense2 = Dense(128, activation='tanh')(concat2)\n",
    "dense2 = Dense(128, activation='tanh')(dense2)\n",
    "sigmoid_layer2 = Dense(1, activation='tanh')(dense2)\n",
    "output2 = Dense(1)(sigmoid_layer2)\n",
    "critic_model2 = Model([state_input2, action_input2], output2)\n",
    "\n",
    "try:\n",
    "    actor_model.load_weights('saves/quanser/actor_model.weights.h5')\n",
    "    critic_model1.load_weights('saves/quanser/critic_model1.weights.h5')\n",
    "    critic_model2.load_weights('saves/quanser/critic_model2.weights.h5')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "actor_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "critic_optimizer1 = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "critic_optimizer2 = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "target_actor = keras.models.clone_model(actor_model)\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "\n",
    "target_critic1 = keras.models.clone_model(critic_model1)\n",
    "target_critic1.set_weights(critic_model1.get_weights())\n",
    "target_critic2 = keras.models.clone_model(critic_model2)\n",
    "target_critic2.set_weights(critic_model2.get_weights())\n",
    "\n",
    "ckpt = tf.train.Checkpoint(actor_optimizer=actor_optimizer,\n",
    "                           critic_optimizer1=critic_optimizer1, \n",
    "                           critic_optimizer2=critic_optimizer2)\n",
    "\n",
    "# Restore the latest checkpoint with optimizer states\n",
    "ckpt.restore(tf.train.latest_checkpoint(\"saves/quanser/optimizers_ckpt\")).expect_partial()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "844cf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency = 500  # Hz\n",
    "# state_theta_dot = np.array([0,0], dtype=np.float64)\n",
    "# state_alpha_dot = np.array([0,0], dtype=np.float64)\n",
    "# with QubeServo3(hardware = 1, pendulum = 1, frequency=frequency) as board:\n",
    "#     while True:\n",
    "#         # Have to initialize the board first before reading motorPosition or it won't read\n",
    "#         board.read_outputs()\n",
    "#         theta = board.motorPosition \n",
    "#         alpha = -board.pendulumPosition \n",
    "#         theta_dot, state_theta_dot = ddt_filter(theta, state_theta_dot, 50, 1/frequency)\n",
    "#         # u - input\n",
    "#         # state - previous state returned by this function -- initialize to np.array([0,0], dtype=np.float64)\n",
    "#         # Ts - sample time in seconds\n",
    "#         # A - filter bandwidth in rad/s\n",
    "#         alpha_dot, state_alpha_dot = ddt_filter(alpha, state_alpha_dot, 100, 1/frequency)\n",
    "#         alpha = np.mod(alpha, 2*np.pi) - np.pi\n",
    "#         alpha = np.cos(alpha)\n",
    "#         theta = np.clip(theta, (-5*np.pi)/8, (5*np.pi)/8)\n",
    "#         reward = -(alpha**2 + 0.0001*alpha_dot**2 )\n",
    "#         print(f\"Theta: {theta:.3f}, Theta dot: {theta_dot:.3f}, Alpha: {alpha:.3f}, Alpha dot: {alpha_dot:.3f}\", \n",
    "#               f\"Reward: {reward:.3f}\")\n",
    "#         time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7442b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntk00\\AppData\\Local\\Temp\\ipykernel_18976\\4143962577.py:69: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  reward = float(reward)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Total Reward: -206.9147, Q1: -2.2614, Q2: -5.9966, TargetQ: -6.9494 alpha: 1.6291 alpha_dot: 191.9058 voltage: -3.00 theta: 1.9635 theta_dot: 58.0561\n",
      "Epoch 400, Total Reward: -392.4622, Q1: -2.1460, Q2: -5.9223, TargetQ: -6.8718 alpha: 2.2795 alpha_dot: 118.4626 voltage: -3.00 theta: 1.9635 theta_dot: 35.0920\n",
      "\n",
      "Stopping (Ctrl+C). Savingâ€¦\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "history = []\n",
    "policy_delay = 2  # Delayed policy updates\n",
    "step = 0\n",
    "total_reward = 0.0\n",
    "frequency = 500  # Hz\n",
    "state_theta_dot = np.array([0,0], dtype=np.float64)\n",
    "state_alpha_dot = np.array([0,0], dtype=np.float64)\n",
    "timestamps = 0 \n",
    "\n",
    "w_theta = 10.0\n",
    "w_alpha = 0.1\n",
    "w_theta_dot = 0.001\n",
    "w_alpha_dot = 0.001\n",
    "w_u = 0.001\n",
    "w_du = 0.3\n",
    "prev_action = np.zeros(action_size, dtype=np.float32)\n",
    "avg_q = []\n",
    "episode_length = 200   # number of control steps per episode\n",
    "step_in_episode = 0\n",
    "try: \n",
    "    with QubeServo3(hardware = 1, pendulum = 1, frequency=10) as board:\n",
    "        while True:\n",
    "            for _ in range(200):  # run at 500 Hz\n",
    "                avg_q1, avg_q2, avg_target_q = 0.0, 0.0, 0.0\n",
    "                step += 1 \n",
    "                board.read_outputs()\n",
    "                theta = board.motorPosition * -1\n",
    "                alpha = board.pendulumPosition \n",
    "                theta = np.clip(theta, (-5*np.pi)/8, (5*np.pi)/8)\n",
    "                alpha = np.mod(alpha, 2*np.pi) - np.pi\n",
    "\n",
    "                theta_dot, state_theta_dot = ddt_filter(theta, state_theta_dot, 50, 1/frequency)\n",
    "                alpha_dot, state_alpha_dot = ddt_filter(alpha, state_alpha_dot, 100, 1/frequency)\n",
    "\n",
    "                state = np.array([theta, theta_dot, alpha, alpha_dot], dtype=np.float32)\n",
    "\n",
    "                action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "                action = action + np.random.normal(0, 0.2, size=action_size)  # Add exploration noise\n",
    "                action = np.clip(action, -2, 2) \n",
    "                board.write_voltage(action)\n",
    "\n",
    "                board.read_outputs()\n",
    "                next_theta = board.motorPosition * -1\n",
    "                next_alpha = board.pendulumPosition\n",
    "                next_alpha = np.mod(next_alpha, 2*np.pi) - np.pi\n",
    "                next_theta = np.clip(next_theta, (-5*np.pi)/8, (5*np.pi)/8)\n",
    "                next_theta_dot, state_theta_dot = ddt_filter(next_theta, state_theta_dot, 50, 1/frequency)\n",
    "                next_alpha_dot, state_alpha_dot = ddt_filter(next_alpha, state_alpha_dot, 100, 1/frequency)\n",
    "                next_state = np.array([next_theta, next_theta_dot, next_alpha, next_alpha_dot], dtype=np.float32)\n",
    "\n",
    "\n",
    "                # wrapped_alpha = ((alpha - np.pi + np.pi) % (2*np.pi)) - np.pi\n",
    "                # reward = -(alpha**2 + 0.0001*alpha_dot**2 + 0.001*action**2)\n",
    "                if abs(theta) <= (5*np.pi/8) and abs(theta_dot) <= 60:\n",
    "                    Fk = 0\n",
    "                else:\n",
    "                    Fk = -1\n",
    "\n",
    "                delta_u = action - prev_action\n",
    "                reward = Fk - ((\n",
    "                    w_theta * (theta**2) +\n",
    "                    w_theta_dot * (theta_dot**2) +\n",
    "                    w_alpha_dot * (alpha_dot**2) +\n",
    "                    w_u * (action**2) +\n",
    "                    w_du * (delta_u**2)\n",
    "                )/100)\n",
    "                prev_action = action.copy()\n",
    "                reward = float(reward)\n",
    "                total_reward += reward\n",
    "\n",
    "                replay_buffer.store(state, action, reward, next_state, False)\n",
    "                state = next_state\n",
    "\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "                states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "                actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
    "                rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "                next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "                dones = tf.convert_to_tensor(dones, dtype=tf.float32) \n",
    "\n",
    "                # add clipped noise to target action\n",
    "                noise = np.random.normal(0, 0.2, size=actions.shape)\n",
    "                next_actions = target_actor(next_states) + noise\n",
    "                next_actions = tf.clip_by_value(next_actions, -2, 2)  # Pendulum action bounds\n",
    "\n",
    "                # Compute target Q-values with both critics\n",
    "                target1 = tf.squeeze(target_critic1([next_states, next_actions]), axis=1)\n",
    "                target2 = tf.squeeze(target_critic2([next_states, next_actions]), axis=1)\n",
    "                target_q = rewards + gamma * (1 - dones) * tf.minimum(target1, target2)\n",
    "\n",
    "                with tf.GradientTape() as tape_critic1, tf.GradientTape() as tape_critic2:\n",
    "                    q1 = critic_model1([states, actions], training=True)\n",
    "                    q2 = critic_model2([states, actions], training=True)\n",
    "\n",
    "                    # Compute losses\n",
    "                    loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "                    loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "\n",
    "                avg_q1 = tf.reduce_mean(q1).numpy().item()\n",
    "                avg_q2 = tf.reduce_mean(q2).numpy().item()\n",
    "                avg_target_q = tf.reduce_mean(target_q).numpy().item()\n",
    "\n",
    "                # Get gradients for each critic once\n",
    "                critic_grad1 = tape_critic1.gradient(loss1, critic_model1.trainable_variables)\n",
    "                critic_grad2 = tape_critic2.gradient(loss2, critic_model2.trainable_variables)\n",
    "\n",
    "                # Apply gradients\n",
    "                critic_optimizer1.apply_gradients(zip(critic_grad1, critic_model1.trainable_variables))\n",
    "                critic_optimizer2.apply_gradients(zip(critic_grad2, critic_model2.trainable_variables))\n",
    "                if step % policy_delay == 0:  # Delayed policy updates\n",
    "                    with tf.GradientTape() as tape_actor: \n",
    "                        action = actor_model(states)\n",
    "                        actor_loss = -tf.reduce_mean(critic_model1([states, action]))\n",
    "\n",
    "                    actor_grad = tape_actor.gradient(actor_loss, actor_model.trainable_variables)\n",
    "                    actor_optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "\n",
    "                    soft_update(target_actor.variables, actor_model.variables, tau=0.005)\n",
    "                    soft_update(target_critic1.variables, critic_model1.variables, tau=0.005)\n",
    "                    soft_update(target_critic2.variables, critic_model2.variables, tau=0.005)\n",
    "\n",
    "            history.append(total_reward)\n",
    "            if step % 1 == 0:\n",
    "                avg_q.append(avg_target_q)\n",
    "                print(f\"Epoch {step}, Total Reward: {float(total_reward):.4f}, \"\n",
    "                f\"Q1: {avg_q1:.4f}, Q2: {avg_q2:.4f}, TargetQ: {avg_target_q:.4f}\", \n",
    "                f\"alpha: {alpha:.4f}\", f\"alpha_dot: {alpha_dot:.4f}\", \n",
    "                f\"voltage: {np.array(action).reshape(-1)[0]:.2f}\", \n",
    "                f\"theta: {theta:.4f}\", f\"theta_dot: {theta_dot:.4f}\")\n",
    "\n",
    "            if step_in_episode >= episode_length:\n",
    "                print(\"Resetting episode...\")\n",
    "                board.write_voltage(0.0)   # stop motor\n",
    "                time.sleep(5.0)            # wait for pendulum to settle down\n",
    "                step_in_episode = 0        # reset counter\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping (Ctrl+C). Savingâ€¦\")\n",
    "finally:\n",
    "    # save weights (use .save_weights if you prefer checkpoint style)\n",
    "    actor_model.save_weights(\"saves/quanser/actor_model.weights.h5\")\n",
    "    critic_model1.save_weights(\"saves/quanser/critic_model1.weights.h5\")\n",
    "    critic_model2.save_weights(\"saves/quanser/critic_model2.weights.h5\")\n",
    "    ckpt = tf.train.Checkpoint(actor_optimizer=actor_optimizer,\n",
    "                           critic_optimizer1=critic_optimizer1,\n",
    "                           critic_optimizer2=critic_optimizer2)\n",
    "    ckpt.save(\"saves/quanser/optimizers_ckpt/ckpt\")\n",
    "    plt.title(\"Average Target Q over Time\")\n",
    "    plt.plot(avg_q, label='Target Q')\n",
    "    plt.legend()\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# history = []\n",
    "# policy_delay = 2  # Delayed policy updates\n",
    "# step = 0\n",
    "# total_reward = 0.0\n",
    "\n",
    "# try:\n",
    "#     total_reward = 0.0\n",
    "#     while True:\n",
    "#         step += 1\n",
    "    \n",
    "#         # 1) read state\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         theta_arm  = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "#         theta_arm_dot  = (theta_arm  - theta_arm_prev)  / dt\n",
    "#         theta_pend_dot = (theta_pend - theta_pend_prev) / dt\n",
    "#         state = np.array([theta_arm, theta_pend, theta_arm_dot, theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # 2) select action\n",
    "#         action_vec = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "#         action_val = float(np.clip(action_vec[0], -2.0, 2.0))  # scalar in [-2,2]; tune to your safe V range\n",
    "\n",
    "#         # 3) apply action (analog write wants numpy float64 buffer)\n",
    "#         voltages = np.array([action_val], dtype=np.float64)\n",
    "#         board.write_analog(motor_channels, len(motor_channels), voltages)\n",
    "\n",
    "#         # 4) get next_state after action\n",
    "#         time.sleep(dt)  # maintain loop timing around the actuation\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         next_theta_arm  = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         next_theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "#         next_theta_arm_dot  = (next_theta_arm  - theta_arm)  / dt\n",
    "#         next_theta_pend_dot = (next_theta_pend - theta_pend) / dt\n",
    "#         next_state = np.array([next_theta_arm, next_theta_pend, next_theta_arm_dot, next_theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # 5) reward (example: upright pendulum, gentle motion)\n",
    "#         reward = - ( (np.angle(np.exp(1j*(next_theta_pend - np.pi))))**2\n",
    "#                      + 0.1*next_theta_pend_dot**2 + 0.01*action_val**2 )\n",
    "#         total_reward += reward\n",
    "\n",
    "#         # 6) store\n",
    "#         replay_buffer.store(state, action_val, reward, next_state, False)\n",
    "\n",
    "#         # 7) train if enough samples\n",
    "#         if replay_buffer.size() >= batch_size:\n",
    "#             states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "#             states      = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "#             actions     = tf.convert_to_tensor(actions.reshape(-1,1), dtype=tf.float32)\n",
    "#             rewards     = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "#             next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "#             dones       = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "\n",
    "#             # target policy smoothing\n",
    "#             noise = np.clip(np.random.normal(0, 0.2, size=(actions.shape[0], 1)), -0.5, 0.5)\n",
    "#             target_act = tf.clip_by_value(target_actor(next_states) + noise, -2.0, 2.0)\n",
    "\n",
    "#             # twin critics target\n",
    "#             t1 = tf.squeeze(target_critic1([next_states, target_act]), axis=1)\n",
    "#             t2 = tf.squeeze(target_critic2([next_states, target_act]), axis=1)\n",
    "#             target_q = rewards + gamma * (1.0 - dones) * tf.minimum(t1, t2)\n",
    "\n",
    "#             # critic updates\n",
    "#             with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "#                 q1 = tf.squeeze(critic_model1([states, actions]), axis=1)\n",
    "#                 q2 = tf.squeeze(critic_model2([states, actions]), axis=1)\n",
    "#                 loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "#                 loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "#             critic_optimizer1.apply_gradients(zip(tape1.gradient(loss1, critic_model1.trainable_variables),\n",
    "#                                                   critic_model1.trainable_variables))\n",
    "#             critic_optimizer2.apply_gradients(zip(tape2.gradient(loss2, critic_model2.trainable_variables),\n",
    "#                                                   critic_model2.trainable_variables))\n",
    "\n",
    "#             # delayed actor + target updates\n",
    "#             if step % policy_delay == 0:\n",
    "#                 with tf.GradientTape() as tape_actor:\n",
    "#                     pi = actor_model(states)\n",
    "#                     actor_loss = -tf.reduce_mean(critic_model1([states, pi]))\n",
    "#                 actor_optimizer.apply_gradients(zip(tape_actor.gradient(actor_loss, actor_model.trainable_variables),\n",
    "#                                                     actor_model.trainable_variables))\n",
    "#                 soft_update(target_actor.variables,   actor_model.variables,   tau=0.005)\n",
    "#                 soft_update(target_critic1.variables, critic_model1.variables, tau=0.005)\n",
    "#                 soft_update(target_critic2.variables, critic_model2.variables, tau=0.005)\n",
    "\n",
    "#         if step % 100 == 0:\n",
    "#             print(f\"Step {step}  reward_sum: {total_reward:.2f}\")\n",
    "\n",
    "#         # update prev angles for next derivative\n",
    "#         theta_arm_prev, theta_pend_prev = next_theta_arm, next_theta_pend\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"\\nStopping (Ctrl+C). Savingâ€¦\")\n",
    "# finally:\n",
    "#     # save weights (use .save_weights if you prefer checkpoint style)\n",
    "#     actor_model.save_weights(\"saves/quanser/actor_model.weights.h5\")\n",
    "#     critic_model1.save_weights(\"saves/quanser/critic_model1.weights.h5\")\n",
    "#     critic_model2.save_weights(\"saves/quanser/critic_model2.weights.h5\")\n",
    "#     # set motor to 0V and close safely\n",
    "#     board.write_analog(motor_channels, 1, np.array([0.0], dtype=np.float64))\n",
    "#     board.close()\n",
    "#     print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff966c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     # read state\n",
    "#     # board.close()\n",
    "#     board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#     theta_arm = counts[0] * ARM_RAD_PER_COUNT\n",
    "#     theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "\n",
    "#     # compute action from policy\n",
    "#     action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "#     u = float(action)\n",
    "\n",
    "#     # send to motor\n",
    "#     board.write_analog(motor_channels, 1, [u])\n",
    "\n",
    "#     time.sleep(dt)  # ~0.01s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598aa56",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QubeServo3' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --- HIL/QUBE setup ---\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m()\n\u001b[0;32m      8\u001b[0m board \u001b[38;5;241m=\u001b[39m HIL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqube_servo3_usb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m encoder_channels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint32)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QubeServo3' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import time\n",
    "# import tensorflow as tf\n",
    "# from collections import deque\n",
    "\n",
    "# # --- HIL/QUBE setup ---\n",
    "# board.close()\n",
    "# board = HIL(\"qube_servo3_usb\", \"0\")\n",
    "# encoder_channels = np.array([0, 1], dtype=np.uint32)\n",
    "# motor_channels = np.array([0], dtype=np.uint32)\n",
    "# counts = np.zeros(2, dtype=np.int32)\n",
    "\n",
    "# ENCODER_RES = 2048\n",
    "# ARM_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "# PEND_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "# dt = 0.01  # 10 ms loop\n",
    "\n",
    "# # --- Replay Buffer ---\n",
    "# class ReplayBuffer:\n",
    "#     def __init__(self, capacity=100000):\n",
    "#         self.buffer = deque(maxlen=capacity)\n",
    "#     def store(self, state, action, reward, next_state, done):\n",
    "#         self.buffer.append((state, action, reward, next_state, done))\n",
    "#     def sample(self, batch_size):\n",
    "#         batch = np.array(random.sample(self.buffer, batch_size))\n",
    "#         states, actions, rewards, next_states, dones = map(np.stack, zip(*batch))\n",
    "#         return states, actions, rewards, next_states, dones\n",
    "#     def size(self):\n",
    "#         return len(self.buffer)\n",
    "\n",
    "# replay_buffer = ReplayBuffer()\n",
    "\n",
    "# # --- Soft update ---\n",
    "# def soft_update(target_weights, online_weights, tau=0.005):\n",
    "#     for (target, online) in zip(target_weights, online_weights):\n",
    "#         target.assign(target * (1 - tau) + online * tau)\n",
    "\n",
    "# # --- TD3 models already defined: actor_model, critic_model1, critic_model2, \n",
    "# # target_actor, target_critic1, target_critic2\n",
    "# # optimizers: actor_optimizer, critic_optimizer1, critic_optimizer2\n",
    "\n",
    "# state_size = 4\n",
    "# action_size = 1\n",
    "# gamma = 0.99\n",
    "# batch_size = 32\n",
    "# policy_delay = 2\n",
    "# step = 0\n",
    "\n",
    "# theta_arm_prev = 0.0\n",
    "# theta_pend_prev = 0.0\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         step += 1\n",
    "\n",
    "#         # --- 1. Read state ---\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         theta_arm = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "\n",
    "#         theta_arm_dot = (theta_arm - theta_arm_prev) / dt\n",
    "#         theta_pend_dot = (theta_pend - theta_pend_prev) / dt\n",
    "#         theta_arm_prev, theta_pend_prev = theta_arm, theta_pend\n",
    "\n",
    "#         state = np.array([theta_arm, theta_pend, theta_arm_dot, theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # --- 2. Compute action ---\n",
    "#         action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "#         u_array = np.array([float(action)], dtype=np.float64)\n",
    "\n",
    "#         # --- 3. Apply action ---\n",
    "#         board.write_analog(motor_channels, 1, u_array)\n",
    "\n",
    "#         # --- 4. Read next state ---\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         next_theta_arm = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         next_theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "#         next_theta_arm_dot = (next_theta_arm - theta_arm) / dt\n",
    "#         next_theta_pend_dot = (next_theta_pend - theta_pend) / dt\n",
    "#         next_state = np.array([next_theta_arm, next_theta_pend, next_theta_arm_dot, next_theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # --- 5. Compute reward ---\n",
    "#         reward = - (next_theta_pend**2 + 0.1 * next_theta_pend_dot**2)\n",
    "\n",
    "#         # --- 6. Store transition ---\n",
    "#         replay_buffer.store(state, action, reward, next_state, False)\n",
    "\n",
    "#         # --- 7. Train TD3 ---\n",
    "#         if replay_buffer.size() >= batch_size:\n",
    "#             states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "#             states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "#             actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
    "#             rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "#             next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "#             dones = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "\n",
    "#             # Target actions with clipped noise\n",
    "#             noise = np.clip(np.random.normal(0, 0.2, size=actions.shape), -0.5, 0.5)\n",
    "#             next_actions = tf.clip_by_value(target_actor(next_states) + noise, -12.0, 12.0)\n",
    "\n",
    "#             # Target Q-values\n",
    "#             target1 = tf.squeeze(target_critic1([next_states, next_actions]), axis=1)\n",
    "#             target2 = tf.squeeze(target_critic2([next_states, next_actions]), axis=1)\n",
    "#             target_q = rewards + gamma * (1 - dones) * tf.minimum(target1, target2)\n",
    "\n",
    "#             # Critic updates\n",
    "#             with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "#                 q1 = critic_model1([states, actions], training=True)\n",
    "#                 q2 = critic_model2([states, actions], training=True)\n",
    "#                 loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "#                 loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "\n",
    "#             critic_grad1 = tape1.gradient(loss1, critic_model1.trainable_variables)\n",
    "#             critic_grad2 = tape2.gradient(loss2, critic_model2.trainable_variables)\n",
    "#             critic_optimizer1.apply_gradients(zip(critic_grad1, critic_model1.trainable_variables))\n",
    "#             critic_optimizer2.apply_gradients(zip(critic_grad2, critic_model2.trainable_variables))\n",
    "\n",
    "#             # Delayed actor update\n",
    "#             if step % policy_delay == 0:\n",
    "#                 with tf.GradientTape() as tape_actor:\n",
    "#                     act = actor_model(states)\n",
    "#                     actor_loss = -tf.reduce_mean(critic_model1([states, act]))\n",
    "#                 actor_grad = tape_actor.gradient(actor_loss, actor_model.trainable_variables)\n",
    "#                 actor_optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "\n",
    "#                 soft_update(target_actor.variables, actor_model.variables)\n",
    "#                 soft_update(target_critic1.variables, critic_model1.variables)\n",
    "#                 soft_update(target_critic2.variables, critic_model2.variables)\n",
    "\n",
    "#         # --- 8. Sleep to maintain loop ---\n",
    "#         time.sleep(dt)\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Stopping (Ctrl+C) and saving models...\")\n",
    "\n",
    "# finally:\n",
    "#     # Save models\n",
    "#     actor_model.save(\"td3_actor.h5\")\n",
    "#     critic_model1.save(\"td3_critic1.h5\")\n",
    "#     critic_model2.save(\"td3_critic2.h5\")\n",
    "#     board.close()\n",
    "#     print(\"Training finished and models saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
