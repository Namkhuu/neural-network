{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8ceea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.layers import Concatenate\n",
    "from collections import deque\n",
    "import random\n",
    "from quanser.hardware import HIL \n",
    "from pal.products.qube import QubeServo3\n",
    "from pal.utilities.math import SignalGenerator, ddt_filter\n",
    "from threading import Thread\n",
    "import time\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8674aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # board.close()\n",
    "# # Open connection to QUBE\n",
    "# # board = HIL(\"qube_servo3_usb\", \"0\")\n",
    "\n",
    "# encoder_channels = np.array([0, 1], dtype=np.uint32)\n",
    "# motor_channels = np.array([0], dtype=np.uint32)\n",
    "# counts = np.zeros(2, dtype=np.int32)\n",
    "\n",
    "# ENCODER_RES = 2048\n",
    "# ARM_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "# PEND_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "\n",
    "# dt = 0.01  # 10 ms\n",
    "# theta_arm_prev  = counts[0] * ARM_RAD_PER_COUNT\n",
    "# theta_pend_prev = counts[1] * PEND_RAD_PER_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49e7c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
    "        return (np.array(states, dtype=np.float32),\n",
    "            np.array(actions, dtype=np.float32),\n",
    "            np.array(rewards, dtype=np.float32),\n",
    "            np.array(next_states, dtype=np.float32),\n",
    "            np.array(dones, dtype=np.float32))\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "def soft_update(target_weights, online_weights, tau=0.005):\n",
    "    for (target, online) in zip(target_weights, online_weights):\n",
    "        target.assign(target * (1 - tau) + online * tau) \n",
    "\n",
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8509c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x27e2397d480>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size = 4\n",
    "action_size = 1\n",
    "gamma = 0.99 # discount rate\n",
    "learning_rate = 0.001 # learning rate\n",
    "\n",
    "# Define the actor model\n",
    "states_inputs = Input(shape=(state_size,))\n",
    "dense = Dense(128, activation='tanh')(states_inputs)\n",
    "dense = Dense(128, activation='tanh')(dense)\n",
    "outputs = Dense(action_size, activation='tanh')(dense)\n",
    "outputs = keras.layers.Lambda(lambda x: x * 2.5)(outputs)  \n",
    "actor_model = Model(inputs=states_inputs, outputs=outputs)\n",
    "\n",
    "# Critic 1\n",
    "state_input1 = Input(shape=(state_size,))\n",
    "action_input1 = Input(shape=(action_size,))\n",
    "concat1 = Concatenate()([state_input1, action_input1])\n",
    "dense1 = Dense(128, activation='tanh')(concat1)\n",
    "dense1 = Dense(128, activation='tanh')(dense1)\n",
    "sigmoid_layer = Dense(1, activation='tanh')(dense1)\n",
    "output1 = Dense(1)(sigmoid_layer)\n",
    "critic_model1 = Model([state_input1, action_input1], output1)\n",
    "\n",
    "# Critic 2\n",
    "state_input2 = Input(shape=(state_size,))\n",
    "action_input2 = Input(shape=(action_size,))\n",
    "concat2 = Concatenate()([state_input2, action_input2])\n",
    "dense2 = Dense(128, activation='tanh')(concat2)\n",
    "dense2 = Dense(128, activation='tanh')(dense2)\n",
    "sigmoid_layer2 = Dense(1, activation='tanh')(dense2)\n",
    "output2 = Dense(1)(sigmoid_layer2)\n",
    "critic_model2 = Model([state_input2, action_input2], output2)\n",
    "\n",
    "# try:\n",
    "#     actor_model.load_weights('saves/quanser/actor_model.weights.h5')\n",
    "#     critic_model1.load_weights('saves/quanser/critic_model1.weights.h5')\n",
    "#     critic_model2.load_weights('saves/quanser/critic_model2.weights.h5')\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "actor_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "critic_optimizer1 = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "critic_optimizer2 = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "target_actor = keras.models.clone_model(actor_model)\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "\n",
    "target_critic1 = keras.models.clone_model(critic_model1)\n",
    "target_critic1.set_weights(critic_model1.get_weights())\n",
    "target_critic2 = keras.models.clone_model(critic_model2)\n",
    "target_critic2.set_weights(critic_model2.get_weights())\n",
    "\n",
    "ckpt = tf.train.Checkpoint(actor_optimizer=actor_optimizer,\n",
    "                           critic_optimizer1=critic_optimizer1, \n",
    "                           critic_optimizer2=critic_optimizer2)\n",
    "\n",
    "# Restore the latest checkpoint with optimizer states\n",
    "ckpt.restore(tf.train.latest_checkpoint(\"saves/quanser/optimizers_ckpt\")).expect_partial()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "844cf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency = 500  # Hz\n",
    "# state_theta_dot = np.array([0,0], dtype=np.float64)\n",
    "# state_alpha_dot = np.array([0,0], dtype=np.float64)\n",
    "# with QubeServo3(hardware = 1, pendulum = 1, frequency=frequency) as board:\n",
    "#     while True:\n",
    "#         # Have to initialize the board first before reading motorPosition or it won't read\n",
    "#         board.read_outputs()\n",
    "#         theta = board.motorPosition \n",
    "#         alpha = -board.pendulumPosition \n",
    "#         theta_dot, state_theta_dot = ddt_filter(theta, state_theta_dot, 50, 1/frequency)\n",
    "#         # u - input\n",
    "#         # state - previous state returned by this function -- initialize to np.array([0,0], dtype=np.float64)\n",
    "#         # Ts - sample time in seconds\n",
    "#         # A - filter bandwidth in rad/s\n",
    "#         alpha_dot, state_alpha_dot = ddt_filter(alpha, state_alpha_dot, 100, 1/frequency)\n",
    "#         alpha = np.mod(alpha, 2*np.pi) - np.pi\n",
    "#         alpha = np.cos(alpha)\n",
    "#         theta = np.clip(theta, (-5*np.pi)/8, (5*np.pi)/8)\n",
    "#         reward = -(alpha**2 + 0.0001*alpha_dot**2 )\n",
    "#         print(f\"Theta: {theta:.3f}, Theta dot: {theta_dot:.3f}, Alpha: {alpha:.3f}, Alpha dot: {alpha_dot:.3f}\", \n",
    "#               f\"Reward: {reward:.3f}\")\n",
    "#         time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7442b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntk00\\AppData\\Local\\Temp\\ipykernel_18676\\4235707799.py:66: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  reward = float(reward)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Total Reward: 0.0000, Q1: -0.1138, Q2: 0.0945, TargetQ: -0.8803 alpha: -3.1416 alpha_dot: -285.5993 voltage: -0.01 theta: -0.0000 theta_dot: 0.0000\n",
      "Epoch 400, Total Reward: -1.1006, Q1: -0.1026, Q2: -0.1613, TargetQ: -1.4683 alpha: -1.6904 alpha_dot: -178.2054 voltage: -1.36 theta: -1.0032 theta_dot: -81.2921\n",
      "Epoch 600, Total Reward: -0.2899, Q1: 0.0625, Q2: -0.2177, TargetQ: -1.3449 alpha: -2.3531 alpha_dot: -8.6593 voltage: -0.54 theta: 1.7027 theta_dot: -9.8042\n",
      "Epoch 800, Total Reward: -1.4001, Q1: -0.1483, Q2: -0.1642, TargetQ: -1.5551 alpha: -2.1537 alpha_dot: 7.0903 voltage: 1.34 theta: 2.0003 theta_dot: 20.0263\n",
      "Epoch 1000, Total Reward: -1.7405, Q1: -0.4079, Q2: -0.2352, TargetQ: -1.6980 alpha: -2.8593 alpha_dot: 2.3925 voltage: -1.07 theta: -2.7213 theta_dot: -1.4923\n",
      "Epoch 1200, Total Reward: -1.7405, Q1: -0.9507, Q2: -0.7298, TargetQ: -2.1064 alpha: -2.8839 alpha_dot: 0.0002 voltage: 1.93 theta: -2.7213 theta_dot: -0.0000\n",
      "Epoch 1400, Total Reward: -1.7405, Q1: -0.7123, Q2: -0.5253, TargetQ: -1.9466 alpha: -2.8839 alpha_dot: 0.0000 voltage: -0.20 theta: -2.7213 theta_dot: -0.0000\n",
      "Epoch 1600, Total Reward: -1.7405, Q1: -0.5901, Q2: -0.4279, TargetQ: -1.8577 alpha: -2.8839 alpha_dot: 0.0000 voltage: 2.00 theta: -2.7213 theta_dot: -0.0000\n",
      "Epoch 1800, Total Reward: -1.7405, Q1: -1.0193, Q2: -0.7066, TargetQ: -2.2475 alpha: -2.8839 alpha_dot: 0.0000 voltage: 1.82 theta: -2.7213 theta_dot: -0.0000\n",
      "Epoch 2000, Total Reward: -1.7405, Q1: -1.0717, Q2: -0.7302, TargetQ: -2.2836 alpha: -2.8839 alpha_dot: 0.0227 voltage: 2.00 theta: -2.7213 theta_dot: -0.0000\n",
      "Epoch 2200, Total Reward: -0.1724, Q1: -1.0033, Q2: -0.6946, TargetQ: -2.0163 alpha: -0.5829 alpha_dot: -10.9668 voltage: 2.00 theta: -1.3131 theta_dot: -41.5406\n",
      "Epoch 2400, Total Reward: -0.0060, Q1: -0.8384, Q2: -0.5819, TargetQ: -1.9366 alpha: -0.9695 alpha_dot: 78.0668 voltage: 2.00 theta: -0.2454 theta_dot: 49.4108\n",
      "Epoch 2600, Total Reward: -1.3491, Q1: -0.8924, Q2: -0.5691, TargetQ: -1.9695 alpha: -1.8530 alpha_dot: -194.4579 voltage: 2.00 theta: -1.8684 theta_dot: -63.7863\n",
      "Epoch 2800, Total Reward: -0.1000, Q1: -1.0844, Q2: -0.7581, TargetQ: -1.8933 alpha: 2.7059 alpha_dot: 61.6434 voltage: 2.00 theta: 1.0002 theta_dot: 57.3430\n",
      "Epoch 3000, Total Reward: -0.3434, Q1: -0.8179, Q2: -0.6079, TargetQ: -1.7846 alpha: -0.6259 alpha_dot: -20.4679 voltage: -2.00 theta: -1.8530 theta_dot: -51.3679\n",
      "Epoch 3200, Total Reward: -0.1366, Q1: -0.7917, Q2: -0.5977, TargetQ: -1.8957 alpha: 0.4725 alpha_dot: -4.3124 voltage: 2.00 theta: -1.1689 theta_dot: -10.1237\n",
      "Epoch 3400, Total Reward: -1.0315, Q1: -0.6924, Q2: -0.5015, TargetQ: -1.6802 alpha: 0.7762 alpha_dot: 58.3847 voltage: -1.94 theta: 0.5614 theta_dot: 64.0112\n",
      "\n",
      "Stopping (Ctrl+C). Saving…\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "history = []\n",
    "policy_delay = 2  # Delayed policy updates\n",
    "step = 0\n",
    "total_reward = 0.0\n",
    "frequency = 500  # Hz\n",
    "state_theta_dot = np.array([0,0], dtype=np.float64)\n",
    "state_alpha_dot = np.array([0,0], dtype=np.float64)\n",
    "timestamps = 0 \n",
    "\n",
    "w_theta = 10.0\n",
    "w_alpha = 0\n",
    "w_theta_dot = 0\n",
    "w_alpha_dot = 0\n",
    "w_u = 0\n",
    "w_du = 0\n",
    "prev_action = np.zeros(action_size, dtype=np.float32)\n",
    "avg_q = []\n",
    "episode_length = 200   # number of control steps per episode\n",
    "step_in_episode = 0\n",
    "try: \n",
    "    with QubeServo3(hardware = 1, pendulum = 1, frequency=10) as board:\n",
    "        while True:\n",
    "            board.read_outputs()\n",
    "            theta = board.motorPosition * -1\n",
    "            alpha = board.pendulumPosition \n",
    "            alpha = np.mod(alpha, 2*np.pi) - np.pi\n",
    "            theta_dot, state_theta_dot = ddt_filter(theta, state_theta_dot, 50, 1/frequency)\n",
    "            alpha_dot, state_alpha_dot = ddt_filter(alpha, state_alpha_dot, 100, 1/frequency)\n",
    "            state = np.array([theta, theta_dot, alpha, alpha_dot], dtype=np.float32)\n",
    "\n",
    "            for _ in range(200):\n",
    "                avg_q1, avg_q2, avg_target_q = 0.0, 0.0, 0.0\n",
    "                step += 1 \n",
    "                \n",
    "                action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "                action = action + np.random.normal(0, 0.3, size=action_size)  # Add exploration noise\n",
    "                # action = np.clip(action, -2, 2) \n",
    "                board.write_voltage(action)\n",
    "\n",
    "                board.read_outputs()\n",
    "                next_theta = board.motorPosition * -1\n",
    "                next_alpha = board.pendulumPosition\n",
    "                next_alpha = np.mod(next_alpha, 2*np.pi) - np.pi\n",
    "                next_theta_dot, state_theta_dot = ddt_filter(next_theta, state_theta_dot, 50, 1/frequency)\n",
    "                next_alpha_dot, state_alpha_dot = ddt_filter(next_alpha, state_alpha_dot, 100, 1/frequency)\n",
    "                next_state = np.array([next_theta, next_theta_dot, next_alpha, next_alpha_dot], dtype=np.float32)\n",
    "\n",
    "\n",
    "                # wrapped_alpha = ((alpha - np.pi + np.pi) % (2*np.pi)) - np.pi\n",
    "                # reward = -(alpha**2 + 0.0001*alpha_dot**2 + 0.001*action**2)\n",
    "                if abs(theta) <= (5*np.pi/8) and abs(theta_dot) <= 60:\n",
    "                    Fk = 0\n",
    "                else:\n",
    "                    Fk = -1\n",
    "\n",
    "                delta_u = action - prev_action\n",
    "                reward = Fk - ((\n",
    "                    w_theta * (theta**2) +\n",
    "                    w_theta_dot * (theta_dot**2) +\n",
    "                    w_alpha_dot * (alpha_dot**2) +\n",
    "                    w_u * (action**2) +\n",
    "                    w_du * (delta_u**2)\n",
    "                )/100)\n",
    "                prev_action = action.copy()\n",
    "                reward = float(reward)\n",
    "                total_reward += reward\n",
    "\n",
    "                replay_buffer.store(state, action, reward, next_state, False)\n",
    "                state = next_state\n",
    "\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "                states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "                actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
    "                rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "                next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "                dones = tf.convert_to_tensor(dones, dtype=tf.float32) \n",
    "\n",
    "                # add clipped noise to target action\n",
    "                noise = tf.random.normal(shape=tf.shape(actions), mean=0.0, stddev=0.3, dtype=tf.float32)\n",
    "                next_actions = target_actor(next_states) + noise\n",
    "                next_actions = tf.clip_by_value(next_actions, -2.0, 2.0)\n",
    "\n",
    "                # Compute target Q-values with both critics\n",
    "                target1 = tf.squeeze(target_critic1([next_states, next_actions]), axis=1)\n",
    "                target2 = tf.squeeze(target_critic2([next_states, next_actions]), axis=1)\n",
    "                target_q = rewards + gamma * (1 - dones) * tf.minimum(target1, target2)\n",
    "                target_q = tf.expand_dims(target_q, axis=1)  # shape (batch,1)\n",
    "                \n",
    "                with tf.GradientTape() as tape_critic1, tf.GradientTape() as tape_critic2:\n",
    "                    q1 = critic_model1([states, actions], training=True)\n",
    "                    q2 = critic_model2([states, actions], training=True)\n",
    "\n",
    "                    # Compute losses\n",
    "                    loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "                    loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "\n",
    "                avg_q1 = tf.reduce_mean(q1).numpy().item()\n",
    "                avg_q2 = tf.reduce_mean(q2).numpy().item()\n",
    "                avg_target_q = tf.reduce_mean(target_q).numpy().item()\n",
    "\n",
    "                # Get gradients for each critic once\n",
    "                critic_grad1 = tape_critic1.gradient(loss1, critic_model1.trainable_variables)\n",
    "                critic_grad2 = tape_critic2.gradient(loss2, critic_model2.trainable_variables)\n",
    "\n",
    "                # Apply gradients\n",
    "                critic_optimizer1.apply_gradients(zip(critic_grad1, critic_model1.trainable_variables))\n",
    "                critic_optimizer2.apply_gradients(zip(critic_grad2, critic_model2.trainable_variables))\n",
    "                if step % policy_delay == 0:  # Delayed policy updates\n",
    "                    with tf.GradientTape() as tape_actor: \n",
    "                        action = actor_model(states)\n",
    "                        actor_loss = -tf.reduce_mean(critic_model1([states, action]))\n",
    "\n",
    "                    actor_grad = tape_actor.gradient(actor_loss, actor_model.trainable_variables)\n",
    "                    actor_optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "\n",
    "                    soft_update(target_actor.variables, actor_model.variables, tau=0.005)\n",
    "                    soft_update(target_critic1.variables, critic_model1.variables, tau=0.005)\n",
    "                    soft_update(target_critic2.variables, critic_model2.variables, tau=0.005)\n",
    "\n",
    "            history.append(total_reward)\n",
    "            if step % 1 == 0:\n",
    "                avg_q.append(avg_target_q)\n",
    "                print(f\"Epoch {step}, Total Reward: {float(reward):.4f}, \"\n",
    "                f\"Q1: {avg_q1:.4f}, Q2: {avg_q2:.4f}, TargetQ: {avg_target_q:.4f}\", \n",
    "                f\"alpha: {alpha:.4f}\", f\"alpha_dot: {alpha_dot:.4f}\", \n",
    "                f\"voltage: {np.array(action).reshape(-1)[0]:.2f}\", \n",
    "                f\"theta: {theta:.4f}\", f\"theta_dot: {theta_dot:.4f}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping (Ctrl+C). Saving…\")\n",
    "finally:\n",
    "    # save weights (use .save_weights if you prefer checkpoint style)\n",
    "    actor_model.save_weights(\"saves/quanser/actor_model.weights.h5\")\n",
    "    critic_model1.save_weights(\"saves/quanser/critic_model1.weights.h5\")\n",
    "    critic_model2.save_weights(\"saves/quanser/critic_model2.weights.h5\")\n",
    "    ckpt = tf.train.Checkpoint(actor_optimizer=actor_optimizer,\n",
    "                           critic_optimizer1=critic_optimizer1,\n",
    "                           critic_optimizer2=critic_optimizer2)\n",
    "    ckpt.save(\"saves/quanser/optimizers_ckpt/ckpt\")\n",
    "    plt.title(\"Average Target Q over Time\")\n",
    "    plt.plot(avg_q, label='Target Q')\n",
    "    plt.legend()\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# history = []\n",
    "# policy_delay = 2  # Delayed policy updates\n",
    "# step = 0\n",
    "# total_reward = 0.0\n",
    "\n",
    "# try:\n",
    "#     total_reward = 0.0\n",
    "#     while True:\n",
    "#         step += 1\n",
    "    \n",
    "#         # 1) read state\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         theta_arm  = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "#         theta_arm_dot  = (theta_arm  - theta_arm_prev)  / dt\n",
    "#         theta_pend_dot = (theta_pend - theta_pend_prev) / dt\n",
    "#         state = np.array([theta_arm, theta_pend, theta_arm_dot, theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # 2) select action\n",
    "#         action_vec = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "#         action_val = float(np.clip(action_vec[0], -2.0, 2.0))  # scalar in [-2,2]; tune to your safe V range\n",
    "\n",
    "#         # 3) apply action (analog write wants numpy float64 buffer)\n",
    "#         voltages = np.array([action_val], dtype=np.float64)\n",
    "#         board.write_analog(motor_channels, len(motor_channels), voltages)\n",
    "\n",
    "#         # 4) get next_state after action\n",
    "#         time.sleep(dt)  # maintain loop timing around the actuation\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         next_theta_arm  = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         next_theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "#         next_theta_arm_dot  = (next_theta_arm  - theta_arm)  / dt\n",
    "#         next_theta_pend_dot = (next_theta_pend - theta_pend) / dt\n",
    "#         next_state = np.array([next_theta_arm, next_theta_pend, next_theta_arm_dot, next_theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # 5) reward (example: upright pendulum, gentle motion)\n",
    "#         reward = - ( (np.angle(np.exp(1j*(next_theta_pend - np.pi))))**2\n",
    "#                      + 0.1*next_theta_pend_dot**2 + 0.01*action_val**2 )\n",
    "#         total_reward += reward\n",
    "\n",
    "#         # 6) store\n",
    "#         replay_buffer.store(state, action_val, reward, next_state, False)\n",
    "\n",
    "#         # 7) train if enough samples\n",
    "#         if replay_buffer.size() >= batch_size:\n",
    "#             states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "#             states      = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "#             actions     = tf.convert_to_tensor(actions.reshape(-1,1), dtype=tf.float32)\n",
    "#             rewards     = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "#             next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "#             dones       = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "\n",
    "#             # target policy smoothing\n",
    "#             noise = np.clip(np.random.normal(0, 0.2, size=(actions.shape[0], 1)), -0.5, 0.5)\n",
    "#             target_act = tf.clip_by_value(target_actor(next_states) + noise, -2.0, 2.0)\n",
    "\n",
    "#             # twin critics target\n",
    "#             t1 = tf.squeeze(target_critic1([next_states, target_act]), axis=1)\n",
    "#             t2 = tf.squeeze(target_critic2([next_states, target_act]), axis=1)\n",
    "#             target_q = rewards + gamma * (1.0 - dones) * tf.minimum(t1, t2)\n",
    "\n",
    "#             # critic updates\n",
    "#             with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "#                 q1 = tf.squeeze(critic_model1([states, actions]), axis=1)\n",
    "#                 q2 = tf.squeeze(critic_model2([states, actions]), axis=1)\n",
    "#                 loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "#                 loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "#             critic_optimizer1.apply_gradients(zip(tape1.gradient(loss1, critic_model1.trainable_variables),\n",
    "#                                                   critic_model1.trainable_variables))\n",
    "#             critic_optimizer2.apply_gradients(zip(tape2.gradient(loss2, critic_model2.trainable_variables),\n",
    "#                                                   critic_model2.trainable_variables))\n",
    "\n",
    "#             # delayed actor + target updates\n",
    "#             if step % policy_delay == 0:\n",
    "#                 with tf.GradientTape() as tape_actor:\n",
    "#                     pi = actor_model(states)\n",
    "#                     actor_loss = -tf.reduce_mean(critic_model1([states, pi]))\n",
    "#                 actor_optimizer.apply_gradients(zip(tape_actor.gradient(actor_loss, actor_model.trainable_variables),\n",
    "#                                                     actor_model.trainable_variables))\n",
    "#                 soft_update(target_actor.variables,   actor_model.variables,   tau=0.005)\n",
    "#                 soft_update(target_critic1.variables, critic_model1.variables, tau=0.005)\n",
    "#                 soft_update(target_critic2.variables, critic_model2.variables, tau=0.005)\n",
    "\n",
    "#         if step % 100 == 0:\n",
    "#             print(f\"Step {step}  reward_sum: {total_reward:.2f}\")\n",
    "\n",
    "#         # update prev angles for next derivative\n",
    "#         theta_arm_prev, theta_pend_prev = next_theta_arm, next_theta_pend\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"\\nStopping (Ctrl+C). Saving…\")\n",
    "# finally:\n",
    "#     # save weights (use .save_weights if you prefer checkpoint style)\n",
    "#     actor_model.save_weights(\"saves/quanser/actor_model.weights.h5\")\n",
    "#     critic_model1.save_weights(\"saves/quanser/critic_model1.weights.h5\")\n",
    "#     critic_model2.save_weights(\"saves/quanser/critic_model2.weights.h5\")\n",
    "#     # set motor to 0V and close safely\n",
    "#     board.write_analog(motor_channels, 1, np.array([0.0], dtype=np.float64))\n",
    "#     board.close()\n",
    "#     print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff966c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     # read state\n",
    "#     # board.close()\n",
    "#     board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#     theta_arm = counts[0] * ARM_RAD_PER_COUNT\n",
    "#     theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "\n",
    "#     # compute action from policy\n",
    "#     action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "#     u = float(action)\n",
    "\n",
    "#     # send to motor\n",
    "#     board.write_analog(motor_channels, 1, [u])\n",
    "\n",
    "#     time.sleep(dt)  # ~0.01s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598aa56",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QubeServo3' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --- HIL/QUBE setup ---\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m()\n\u001b[0;32m      8\u001b[0m board \u001b[38;5;241m=\u001b[39m HIL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqube_servo3_usb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m encoder_channels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint32)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QubeServo3' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import time\n",
    "# import tensorflow as tf\n",
    "# from collections import deque\n",
    "\n",
    "# # --- HIL/QUBE setup ---\n",
    "# board.close()\n",
    "# board = HIL(\"qube_servo3_usb\", \"0\")\n",
    "# encoder_channels = np.array([0, 1], dtype=np.uint32)\n",
    "# motor_channels = np.array([0], dtype=np.uint32)\n",
    "# counts = np.zeros(2, dtype=np.int32)\n",
    "\n",
    "# ENCODER_RES = 2048\n",
    "# ARM_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "# PEND_RAD_PER_COUNT = 2*np.pi / ENCODER_RES\n",
    "# dt = 0.01  # 10 ms loop\n",
    "\n",
    "# # --- Replay Buffer ---\n",
    "# class ReplayBuffer:\n",
    "#     def __init__(self, capacity=100000):\n",
    "#         self.buffer = deque(maxlen=capacity)\n",
    "#     def store(self, state, action, reward, next_state, done):\n",
    "#         self.buffer.append((state, action, reward, next_state, done))\n",
    "#     def sample(self, batch_size):\n",
    "#         batch = np.array(random.sample(self.buffer, batch_size))\n",
    "#         states, actions, rewards, next_states, dones = map(np.stack, zip(*batch))\n",
    "#         return states, actions, rewards, next_states, dones\n",
    "#     def size(self):\n",
    "#         return len(self.buffer)\n",
    "\n",
    "# replay_buffer = ReplayBuffer()\n",
    "\n",
    "# # --- Soft update ---\n",
    "# def soft_update(target_weights, online_weights, tau=0.005):\n",
    "#     for (target, online) in zip(target_weights, online_weights):\n",
    "#         target.assign(target * (1 - tau) + online * tau)\n",
    "\n",
    "# # --- TD3 models already defined: actor_model, critic_model1, critic_model2, \n",
    "# # target_actor, target_critic1, target_critic2\n",
    "# # optimizers: actor_optimizer, critic_optimizer1, critic_optimizer2\n",
    "\n",
    "# state_size = 4\n",
    "# action_size = 1\n",
    "# gamma = 0.99\n",
    "# batch_size = 32\n",
    "# policy_delay = 2\n",
    "# step = 0\n",
    "\n",
    "# theta_arm_prev = 0.0\n",
    "# theta_pend_prev = 0.0\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         step += 1\n",
    "\n",
    "#         # --- 1. Read state ---\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         theta_arm = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "\n",
    "#         theta_arm_dot = (theta_arm - theta_arm_prev) / dt\n",
    "#         theta_pend_dot = (theta_pend - theta_pend_prev) / dt\n",
    "#         theta_arm_prev, theta_pend_prev = theta_arm, theta_pend\n",
    "\n",
    "#         state = np.array([theta_arm, theta_pend, theta_arm_dot, theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # --- 2. Compute action ---\n",
    "#         action = actor_model(tf.convert_to_tensor([state], dtype=tf.float32)).numpy()[0]\n",
    "#         u_array = np.array([float(action)], dtype=np.float64)\n",
    "\n",
    "#         # --- 3. Apply action ---\n",
    "#         board.write_analog(motor_channels, 1, u_array)\n",
    "\n",
    "#         # --- 4. Read next state ---\n",
    "#         board.read_encoder(encoder_channels, len(encoder_channels), counts)\n",
    "#         next_theta_arm = counts[0] * ARM_RAD_PER_COUNT\n",
    "#         next_theta_pend = counts[1] * PEND_RAD_PER_COUNT\n",
    "#         next_theta_arm_dot = (next_theta_arm - theta_arm) / dt\n",
    "#         next_theta_pend_dot = (next_theta_pend - theta_pend) / dt\n",
    "#         next_state = np.array([next_theta_arm, next_theta_pend, next_theta_arm_dot, next_theta_pend_dot], dtype=np.float32)\n",
    "\n",
    "#         # --- 5. Compute reward ---\n",
    "#         reward = - (next_theta_pend**2 + 0.1 * next_theta_pend_dot**2)\n",
    "\n",
    "#         # --- 6. Store transition ---\n",
    "#         replay_buffer.store(state, action, reward, next_state, False)\n",
    "\n",
    "#         # --- 7. Train TD3 ---\n",
    "#         if replay_buffer.size() >= batch_size:\n",
    "#             states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "#             states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "#             actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
    "#             rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "#             next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "#             dones = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "\n",
    "#             # Target actions with clipped noise\n",
    "#             noise = np.clip(np.random.normal(0, 0.2, size=actions.shape), -0.5, 0.5)\n",
    "#             next_actions = tf.clip_by_value(target_actor(next_states) + noise, -12.0, 12.0)\n",
    "\n",
    "#             # Target Q-values\n",
    "#             target1 = tf.squeeze(target_critic1([next_states, next_actions]), axis=1)\n",
    "#             target2 = tf.squeeze(target_critic2([next_states, next_actions]), axis=1)\n",
    "#             target_q = rewards + gamma * (1 - dones) * tf.minimum(target1, target2)\n",
    "\n",
    "#             # Critic updates\n",
    "#             with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "#                 q1 = critic_model1([states, actions], training=True)\n",
    "#                 q2 = critic_model2([states, actions], training=True)\n",
    "#                 loss1 = tf.keras.losses.MSE(target_q, q1)\n",
    "#                 loss2 = tf.keras.losses.MSE(target_q, q2)\n",
    "\n",
    "#             critic_grad1 = tape1.gradient(loss1, critic_model1.trainable_variables)\n",
    "#             critic_grad2 = tape2.gradient(loss2, critic_model2.trainable_variables)\n",
    "#             critic_optimizer1.apply_gradients(zip(critic_grad1, critic_model1.trainable_variables))\n",
    "#             critic_optimizer2.apply_gradients(zip(critic_grad2, critic_model2.trainable_variables))\n",
    "\n",
    "#             # Delayed actor update\n",
    "#             if step % policy_delay == 0:\n",
    "#                 with tf.GradientTape() as tape_actor:\n",
    "#                     act = actor_model(states)\n",
    "#                     actor_loss = -tf.reduce_mean(critic_model1([states, act]))\n",
    "#                 actor_grad = tape_actor.gradient(actor_loss, actor_model.trainable_variables)\n",
    "#                 actor_optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "\n",
    "#                 soft_update(target_actor.variables, actor_model.variables)\n",
    "#                 soft_update(target_critic1.variables, critic_model1.variables)\n",
    "#                 soft_update(target_critic2.variables, critic_model2.variables)\n",
    "\n",
    "#         # --- 8. Sleep to maintain loop ---\n",
    "#         time.sleep(dt)\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Stopping (Ctrl+C) and saving models...\")\n",
    "\n",
    "# finally:\n",
    "#     # Save models\n",
    "#     actor_model.save(\"td3_actor.h5\")\n",
    "#     critic_model1.save(\"td3_critic1.h5\")\n",
    "#     critic_model2.save(\"td3_critic2.h5\")\n",
    "#     board.close()\n",
    "#     print(\"Training finished and models saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
